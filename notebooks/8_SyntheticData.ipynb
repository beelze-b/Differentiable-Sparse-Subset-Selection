{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we know that Gumbel selects things relatively well. Its effects of Zeisel though are a bit muddled because of reconstruction. Let's do a simple synethetic dataset. Half the features are real. Half the features at noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import functional as F\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "#from sklearn.manifold import TSNE\n",
    "\n",
    "#import math\n",
    "\n",
    "#import gc\n",
    "\n",
    "from utils import *\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BASE_PATH_DATA = '../data/'\n",
    "BASE_PATH_DATA = '/scratch/ns3429/sparse-subset/data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# really good results for vanilla VAE on synthetic data with EPOCHS set to 50, \n",
    "# but when running locally set to 10 for reasonable run times\n",
    "n_epochs = 20\n",
    "#n_epochs = 20\n",
    "batch_size = 64\n",
    "lr = 0.0001\n",
    "b1 = 0.9\n",
    "b2 = 0.999\n",
    "\n",
    "\n",
    "# from running\n",
    "# EPSILON = np.finfo(tf.float32.as_numpy_dtype).tiny\n",
    "#EPSILON = 1.1754944e-38\n",
    "EPSILON = 1e-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda = True if torch.cuda.is_available() else False\n",
    "\n",
    "Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor\n",
    "\n",
    "device = torch.device(\"cuda:0\" if cuda else \"cpu\")\n",
    "#device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "print(\"Device\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = 30\n",
    "N = 5000\n",
    "z_size = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_data = np.random.normal(loc=0.0, scale=1.0, size=N*z_size).reshape(N, z_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=5, out_features=10, bias=False)\n",
       "  (1): Tanh()\n",
       "  (2): Linear(in_features=10, out_features=30, bias=True)\n",
       "  (3): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_mapper = nn.Sequential(\n",
    "    nn.Linear(z_size, 2 * z_size, bias=False),\n",
    "    nn.Tanh(),\n",
    "    nn.Linear(2 * z_size, D, bias = True),\n",
    "    nn.ReLU()\n",
    ").to(device)\n",
    "\n",
    "data_mapper.requires_grad_(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.7641,  0.4002,  0.9787,  2.2409,  1.8676],\n",
       "        [-0.9773,  0.9501, -0.1514, -0.1032,  0.4106],\n",
       "        [ 0.1440,  1.4543,  0.7610,  0.1217,  0.4439],\n",
       "        ...,\n",
       "        [ 0.2501, -1.0168,  0.0459,  0.5006,  1.2243],\n",
       "        [-0.5595,  1.5234, -0.5857,  0.8466, -0.1063],\n",
       "        [ 0.7700,  0.7508, -0.5606, -1.7603,  0.4371]], device='cuda:0')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latent_data = Tensor(latent_data)\n",
    "latent_data.requires_grad_(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_data = data_mapper(latent_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(19, device='cuda:0')\n",
      "tensor(12, device='cuda:0')\n",
      "tensor(18, device='cuda:0')\n",
      "tensor(14, device='cuda:0')\n",
      "tensor(14, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(torch.sum(actual_data[i,:] != 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each sample, half the data is non zero, whereas in zeisel, about 25% if non zero. Easier than Zeisel good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.0921e-02, -6.1085e-04, -1.4928e-02,  ..., -1.4309e-02,\n",
       "          1.6859e-02, -1.2177e-02],\n",
       "        [ 7.6496e-03,  1.1971e-02, -2.2414e-02,  ...,  1.0256e-02,\n",
       "         -5.5957e-03,  4.3434e-03],\n",
       "        [ 2.7566e-03,  1.0969e-03,  3.5942e-03,  ...,  6.0039e-03,\n",
       "          8.7524e-04,  7.0365e-03],\n",
       "        ...,\n",
       "        [ 1.8449e-02,  8.3797e-04, -8.9499e-03,  ...,  8.9735e-04,\n",
       "         -1.6982e-03,  7.8153e-03],\n",
       "        [-1.0649e-02, -9.6204e-03, -8.1562e-03,  ..., -2.2612e-04,\n",
       "         -1.4104e-02, -8.2127e-03],\n",
       "        [ 2.1183e-02, -1.1416e-02,  1.8769e-03,  ..., -1.3100e-02,\n",
       "         -6.2333e-03, -4.3646e-05]], device='cuda:0')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noise_features = torch.empty(N * D).normal_(mean=0,std=0.01).reshape(N, D).to(device)\n",
    "noise_features.requires_grad_(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_data = torch.cat([actual_data, noise_features], dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5000, 60])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_data = actual_data.cpu().numpy()\n",
    "scaler = MinMaxScaler()\n",
    "actual_data = scaler.fit_transform(actual_data)\n",
    "\n",
    "actual_data = Tensor(actual_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1866, 0.2313, 0.2054, 0.2209, 0.2323, 0.1899, 0.1801, 0.1969, 0.1133,\n",
       "        0.2353, 0.0925, 0.1310, 0.1725, 0.1902, 0.2294, 0.2275, 0.2082, 0.0530,\n",
       "        0.0980, 0.1738, 0.1728, 0.2156, 0.0460, 0.0932, 0.0255, 0.1816, 0.1587,\n",
       "        0.2263, 0.2125, 0.2393, 0.1326, 0.1439, 0.1281, 0.1421, 0.1297, 0.1413,\n",
       "        0.1492, 0.1272, 0.1233, 0.1420, 0.1422, 0.1363, 0.1256, 0.1288, 0.1377,\n",
       "        0.1438, 0.1337, 0.1331, 0.1258, 0.1346, 0.1507, 0.1223, 0.1429, 0.1343,\n",
       "        0.1348, 0.1361, 0.1388, 0.1391, 0.1426, 0.1383], device='cuda:0')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual_data.std(dim = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standard deviatiosn are comparable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.max(\n",
       "values=tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0'),\n",
       "indices=tensor([ 738, 4262, 1553, 1484, 2220, 1316, 3892, 1316, 3121, 3883, 1838,  623,\n",
       "        1004, 4856,  689, 2033, 2038, 1316, 4515, 4562, 4668,  616,  894, 4515,\n",
       "        1885, 3892, 4615,  819, 4397, 4293,  713, 2220, 3813, 4659, 4389, 3659,\n",
       "         309, 1804,  495, 4790, 3110, 4671,   36,    0, 1215,  148, 4008, 1317,\n",
       "        2503, 1402, 1580, 2684, 4078, 3334, 1376, 2499, 1301, 3114, 4203, 3183],\n",
       "       device='cuda:0'))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual_data.max(dim = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.min(\n",
       "values=tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0'),\n",
       "indices=tensor([   1,    8,    0,    1,    0,    5,    1,    1,    1,    0,    1,    1,\n",
       "           0,   13,    3,    3,    1,    0,    0,    1,    1,    8,    0,    0,\n",
       "           0,    1,  254,    4,    0,    0,  454, 3677, 1909, 3750, 3638, 4476,\n",
       "         553, 4105,  289, 1150, 2707, 1846, 3579, 3101,  299, 1324, 3277, 4318,\n",
       "        3023,  967, 2932, 3588,  919, 1190,  271, 2937, 3428, 3955, 2719,  198],\n",
       "       device='cuda:0'))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual_data.min(dim = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(49, device='cuda:0')\n",
      "tensor(42, device='cuda:0')\n",
      "tensor(48, device='cuda:0')\n",
      "tensor(44, device='cuda:0')\n",
      "tensor(44, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(torch.sum(actual_data[i,:] != 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "slices = np.random.permutation(np.arange(actual_data.shape[0]))\n",
    "upto = int(.8 * len(actual_data))\n",
    "\n",
    "train_data = actual_data[slices[:upto]]\n",
    "test_data = actual_data[slices[upto:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4000, 60])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 60])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairwise_correlations(dataset):\n",
    "    cor_df = np.zeros((dataset.shape[1], dataset.shape[1]))\n",
    "    for row in np.arange(dataset.shape[1]):\n",
    "        for col in np.arange(dataset.shape[1]):\n",
    "            cor_df[row, col] = pearsonr(dataset[row], dataset[col])[0]\n",
    "    return cor_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "2\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "actual_data_clone = actual_data.clone().detach().cpu().numpy()\n",
    "\n",
    "pairwise_cor_df = pairwise_correlations(actual_data_clone)\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "sns.heatmap(pairwise_cor_df)\n",
    "\n",
    "correlates = []\n",
    "for i in range(2 * D):\n",
    "    one = np.sum(np.abs(pairwise_cor_df[i, :D]))\n",
    "    two = np.sum(np.abs(pairwise_cor_df[i, D:2*D]))\n",
    "    #correlates.append([one, two])\n",
    "    correlates.append(one > two)\n",
    "    \n",
    "# correlation of that feature with the first 30 features and the second 30 features\n",
    "print(np.sum(correlates[:D]))\n",
    "\n",
    "print(np.sum(correlates[D:2*D]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now run all of the notebook or just the last part focusing on gumbel vs gradients on truncated (or not) losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data is all ready. Now time to feed into into a pretraining-matching Gumbel and joint training Gumbel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre train VAE First"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrain_vae = VAE(2*D, 100, 20)\n",
    "\n",
    "pretrain_vae.to(device)\n",
    "pretrain_vae_optimizer = torch.optim.Adam(pretrain_vae.parameters(), \n",
    "                                            lr=lr,\n",
    "                                            betas = (b1,b2))\n",
    "\n",
    "#pretrain_vae_optimizer = torch.optim.SGD(pretrain_vae.parameters(), \n",
    "#                                            lr=lr, momentum = 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/4000 (0%)]\tLoss: 42.040878\n",
      "Train Epoch: 1 [1280/4000 (32%)]\tLoss: 41.438320\n",
      "Train Epoch: 1 [2560/4000 (64%)]\tLoss: 40.925156\n",
      "Train Epoch: 1 [3840/4000 (96%)]\tLoss: 40.317234\n",
      "====> Epoch: 1 Average loss: 41.1614\n",
      "====> Test set loss: 40.2349\n",
      "Train Epoch: 2 [0/4000 (0%)]\tLoss: 40.268456\n",
      "Train Epoch: 2 [1280/4000 (32%)]\tLoss: 39.820087\n",
      "Train Epoch: 2 [2560/4000 (64%)]\tLoss: 39.064011\n",
      "Train Epoch: 2 [3840/4000 (96%)]\tLoss: 38.332138\n",
      "====> Epoch: 2 Average loss: 39.3663\n",
      "====> Test set loss: 38.3062\n",
      "Train Epoch: 3 [0/4000 (0%)]\tLoss: 38.370636\n",
      "Train Epoch: 3 [1280/4000 (32%)]\tLoss: 37.520363\n",
      "Train Epoch: 3 [2560/4000 (64%)]\tLoss: 36.419781\n",
      "Train Epoch: 3 [3840/4000 (96%)]\tLoss: 36.041069\n",
      "====> Epoch: 3 Average loss: 36.9965\n",
      "====> Test set loss: 35.6713\n",
      "Train Epoch: 4 [0/4000 (0%)]\tLoss: 35.697887\n",
      "Train Epoch: 4 [1280/4000 (32%)]\tLoss: 35.314838\n",
      "Train Epoch: 4 [2560/4000 (64%)]\tLoss: 34.737511\n",
      "Train Epoch: 4 [3840/4000 (96%)]\tLoss: 34.284576\n",
      "====> Epoch: 4 Average loss: 35.0459\n",
      "====> Test set loss: 34.5482\n",
      "Train Epoch: 5 [0/4000 (0%)]\tLoss: 34.687443\n",
      "Train Epoch: 5 [1280/4000 (32%)]\tLoss: 34.266811\n",
      "Train Epoch: 5 [2560/4000 (64%)]\tLoss: 34.175262\n",
      "Train Epoch: 5 [3840/4000 (96%)]\tLoss: 34.272411\n",
      "====> Epoch: 5 Average loss: 34.2673\n",
      "====> Test set loss: 34.0695\n",
      "Train Epoch: 6 [0/4000 (0%)]\tLoss: 34.298531\n",
      "Train Epoch: 6 [1280/4000 (32%)]\tLoss: 33.982563\n",
      "Train Epoch: 6 [2560/4000 (64%)]\tLoss: 33.783413\n",
      "Train Epoch: 6 [3840/4000 (96%)]\tLoss: 34.032188\n",
      "====> Epoch: 6 Average loss: 33.9042\n",
      "====> Test set loss: 33.6989\n",
      "Train Epoch: 7 [0/4000 (0%)]\tLoss: 33.484715\n",
      "Train Epoch: 7 [1280/4000 (32%)]\tLoss: 34.202930\n",
      "Train Epoch: 7 [2560/4000 (64%)]\tLoss: 33.637295\n",
      "Train Epoch: 7 [3840/4000 (96%)]\tLoss: 33.302711\n",
      "====> Epoch: 7 Average loss: 33.6397\n",
      "====> Test set loss: 33.5267\n",
      "Train Epoch: 8 [0/4000 (0%)]\tLoss: 33.852386\n",
      "Train Epoch: 8 [1280/4000 (32%)]\tLoss: 33.054916\n",
      "Train Epoch: 8 [2560/4000 (64%)]\tLoss: 33.295441\n",
      "Train Epoch: 8 [3840/4000 (96%)]\tLoss: 33.458359\n",
      "====> Epoch: 8 Average loss: 33.4518\n",
      "====> Test set loss: 33.3338\n",
      "Train Epoch: 9 [0/4000 (0%)]\tLoss: 33.379860\n",
      "Train Epoch: 9 [1280/4000 (32%)]\tLoss: 33.245426\n",
      "Train Epoch: 9 [2560/4000 (64%)]\tLoss: 33.015312\n",
      "Train Epoch: 9 [3840/4000 (96%)]\tLoss: 33.306889\n",
      "====> Epoch: 9 Average loss: 33.3004\n",
      "====> Test set loss: 33.1792\n",
      "Train Epoch: 10 [0/4000 (0%)]\tLoss: 33.196507\n",
      "Train Epoch: 10 [1280/4000 (32%)]\tLoss: 33.492531\n",
      "Train Epoch: 10 [2560/4000 (64%)]\tLoss: 33.017139\n",
      "Train Epoch: 10 [3840/4000 (96%)]\tLoss: 33.179092\n",
      "====> Epoch: 10 Average loss: 33.1650\n",
      "====> Test set loss: 33.0586\n",
      "Train Epoch: 11 [0/4000 (0%)]\tLoss: 33.406693\n",
      "Train Epoch: 11 [1280/4000 (32%)]\tLoss: 32.915253\n",
      "Train Epoch: 11 [2560/4000 (64%)]\tLoss: 33.039219\n",
      "Train Epoch: 11 [3840/4000 (96%)]\tLoss: 32.731422\n",
      "====> Epoch: 11 Average loss: 33.0133\n",
      "====> Test set loss: 32.8865\n",
      "Train Epoch: 12 [0/4000 (0%)]\tLoss: 32.985565\n",
      "Train Epoch: 12 [1280/4000 (32%)]\tLoss: 32.534718\n",
      "Train Epoch: 12 [2560/4000 (64%)]\tLoss: 33.025467\n",
      "Train Epoch: 12 [3840/4000 (96%)]\tLoss: 32.744030\n",
      "====> Epoch: 12 Average loss: 32.8752\n",
      "====> Test set loss: 32.7545\n",
      "Train Epoch: 13 [0/4000 (0%)]\tLoss: 33.050987\n",
      "Train Epoch: 13 [1280/4000 (32%)]\tLoss: 32.862495\n",
      "Train Epoch: 13 [2560/4000 (64%)]\tLoss: 33.030533\n",
      "Train Epoch: 13 [3840/4000 (96%)]\tLoss: 32.523941\n",
      "====> Epoch: 13 Average loss: 32.6995\n",
      "====> Test set loss: 32.5549\n",
      "Train Epoch: 14 [0/4000 (0%)]\tLoss: 32.347900\n",
      "Train Epoch: 14 [1280/4000 (32%)]\tLoss: 32.593693\n",
      "Train Epoch: 14 [2560/4000 (64%)]\tLoss: 32.556351\n",
      "Train Epoch: 14 [3840/4000 (96%)]\tLoss: 32.544231\n",
      "====> Epoch: 14 Average loss: 32.5194\n",
      "====> Test set loss: 32.3930\n",
      "Train Epoch: 15 [0/4000 (0%)]\tLoss: 32.393734\n",
      "Train Epoch: 15 [1280/4000 (32%)]\tLoss: 32.552738\n",
      "Train Epoch: 15 [2560/4000 (64%)]\tLoss: 32.707394\n",
      "Train Epoch: 15 [3840/4000 (96%)]\tLoss: 32.203064\n",
      "====> Epoch: 15 Average loss: 32.3426\n",
      "====> Test set loss: 32.1875\n",
      "Train Epoch: 16 [0/4000 (0%)]\tLoss: 32.645744\n",
      "Train Epoch: 16 [1280/4000 (32%)]\tLoss: 31.644199\n",
      "Train Epoch: 16 [2560/4000 (64%)]\tLoss: 31.811872\n",
      "Train Epoch: 16 [3840/4000 (96%)]\tLoss: 32.148647\n",
      "====> Epoch: 16 Average loss: 32.1739\n",
      "====> Test set loss: 32.0428\n",
      "Train Epoch: 17 [0/4000 (0%)]\tLoss: 32.033478\n",
      "Train Epoch: 17 [1280/4000 (32%)]\tLoss: 32.131413\n",
      "Train Epoch: 17 [2560/4000 (64%)]\tLoss: 32.186337\n",
      "Train Epoch: 17 [3840/4000 (96%)]\tLoss: 31.633179\n",
      "====> Epoch: 17 Average loss: 32.0474\n",
      "====> Test set loss: 31.9304\n",
      "Train Epoch: 18 [0/4000 (0%)]\tLoss: 32.035835\n",
      "Train Epoch: 18 [1280/4000 (32%)]\tLoss: 31.824549\n",
      "Train Epoch: 18 [2560/4000 (64%)]\tLoss: 31.860462\n",
      "Train Epoch: 18 [3840/4000 (96%)]\tLoss: 31.746033\n",
      "====> Epoch: 18 Average loss: 31.9287\n",
      "====> Test set loss: 31.7941\n",
      "Train Epoch: 19 [0/4000 (0%)]\tLoss: 32.093262\n",
      "Train Epoch: 19 [1280/4000 (32%)]\tLoss: 31.827209\n",
      "Train Epoch: 19 [2560/4000 (64%)]\tLoss: 31.592600\n",
      "Train Epoch: 19 [3840/4000 (96%)]\tLoss: 31.730757\n",
      "====> Epoch: 19 Average loss: 31.8326\n",
      "====> Test set loss: 31.7190\n",
      "Train Epoch: 20 [0/4000 (0%)]\tLoss: 31.849550\n",
      "Train Epoch: 20 [1280/4000 (32%)]\tLoss: 31.911125\n",
      "Train Epoch: 20 [2560/4000 (64%)]\tLoss: 31.826286\n",
      "Train Epoch: 20 [3840/4000 (96%)]\tLoss: 31.669199\n",
      "====> Epoch: 20 Average loss: 31.6939\n",
      "====> Test set loss: 31.6303\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, n_epochs + 1):\n",
    "    train(train_data, pretrain_vae, pretrain_vae_optimizer, epoch, batch_size)\n",
    "    test(test_data, pretrain_vae, epoch, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss\n",
      "tensor(0.5149, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    print(\"Test Loss\")\n",
    "    print(F.binary_cross_entropy(pretrain_vae(test_data)[0], test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actually pretty good! %35 percent off when wrong\n",
    "\n",
    "Get 0.49 when nepochs is 50.\n",
    "Get 0.54 when nepochs is 10."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a note, if the final layer of the data mapper is not ReLU, this reconstruction is usually on point. When some of the features can be sparse, then this becomes troublesome."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0931, 0.3051, 0.1384, 0.2096, 0.2092, 0.2112, 0.1042, 0.2325, 0.0347,\n",
       "        0.2014, 0.0244, 0.0502, 0.0919, 0.2735, 0.2254, 0.3294, 0.2786, 0.0084,\n",
       "        0.0338, 0.1001, 0.0849, 0.2512, 0.0048, 0.0257, 0.0015, 0.0874, 0.4764,\n",
       "        0.3270, 0.2107, 0.2899], device='cuda:0')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.mean(dim = 0)[:D]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0978, 0.3031, 0.1394, 0.2099, 0.2063, 0.2098, 0.1076, 0.2316, 0.0298,\n",
       "        0.1968, 0.0261, 0.0561, 0.0848, 0.2727, 0.2320, 0.3355, 0.2739, 0.0056,\n",
       "        0.0301, 0.0953, 0.0889, 0.2483, 0.0063, 0.0231, 0.0009, 0.0924, 0.4782,\n",
       "        0.3251, 0.2092, 0.2881], device='cuda:0')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.mean(dim = 0)[:D]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1002, 0.3100, 0.1476, 0.2128, 0.2175, 0.2078, 0.1165, 0.2329, 0.0379,\n",
       "        0.2061, 0.0331, 0.0601, 0.0990, 0.2806, 0.2365, 0.3387, 0.2734, 0.0217,\n",
       "        0.0397, 0.0952, 0.1013, 0.2564, 0.0201, 0.0326, 0.0182, 0.1010, 0.4756,\n",
       "        0.3285, 0.2208, 0.2978], device='cuda:0', grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrain_vae(test_data)[0].mean(dim = 0)[:D]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare standard deviations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1913, 0.2338, 0.2076, 0.2199, 0.2306, 0.1890, 0.1805, 0.1945, 0.1051,\n",
       "        0.2321, 0.0976, 0.1389, 0.1652, 0.1922, 0.2341, 0.2330, 0.2048, 0.0390,\n",
       "        0.0929, 0.1692, 0.1755, 0.2236, 0.0499, 0.0923, 0.0152, 0.1863, 0.1593,\n",
       "        0.2244, 0.2096, 0.2350], device='cuda:0')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.std(dim = 0)[:D]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0867, 0.1243, 0.1361, 0.1189, 0.1213, 0.0693, 0.1257, 0.1406, 0.0439,\n",
       "        0.1372, 0.0388, 0.0622, 0.0814, 0.1616, 0.2062, 0.2019, 0.0923, 0.0244,\n",
       "        0.0393, 0.0729, 0.1034, 0.1457, 0.0285, 0.0343, 0.0240, 0.1338, 0.0751,\n",
       "        0.1946, 0.0811, 0.1522], device='cuda:0', grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrain_vae(test_data)[0].std(dim = 0)[:D]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0203, 0.0233, 0.0177, 0.0187, 0.0195, 0.0208, 0.0190, 0.0217, 0.0194,\n",
       "        0.0207, 0.0201, 0.0231, 0.0224, 0.0179, 0.0207, 0.0183, 0.0188, 0.0193,\n",
       "        0.0163, 0.0222, 0.0184, 0.0201, 0.0237, 0.0217, 0.0185, 0.0215, 0.0213,\n",
       "        0.0240, 0.0228, 0.0213], device='cuda:0', grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrain_vae(test_data)[0].std(dim = 0)[D:2*D]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_std = pretrain_vae(test_data)[0].std(dim = 0)[:D] / test_data.std(dim = 0)[:D]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4556, 0.5455, 0.6610, 0.5579, 0.5544, 0.3877, 0.6828, 0.7254, 0.4056,\n",
      "        0.6084, 0.4012, 0.4387, 0.5227, 0.8498, 0.8759, 0.8662, 0.4676, 0.6447,\n",
      "        0.4209, 0.4263, 0.5817, 0.6613, 0.5605, 0.3631, 1.5810, 0.7067, 0.4824,\n",
      "        0.8679, 0.4042, 0.6486], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "0.6118571162223816\n"
     ]
    }
   ],
   "source": [
    "print(average_std)\n",
    "print(average_std.mean().item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get .8 as the mean when nepoch is 50. Get 0.43 as the mean when nepochs is 10."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "samp = 45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 0.5286, 0.0000, 0.0231, 0.6963, 0.3966, 0.0103, 0.2939, 0.0000,\n",
       "        0.3152, 0.0000, 0.0000, 0.0000, 0.0617, 0.4150, 0.6262, 0.2110, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.6829, 0.0000, 0.0000, 0.0000, 0.0000, 0.3516,\n",
       "        0.0000, 0.6491, 0.4560], device='cuda:0')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[samp,:D]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0299, 0.2970, 0.0424, 0.2183, 0.3280, 0.2362, 0.0718, 0.2682, 0.0160,\n",
       "        0.1803, 0.0128, 0.0275, 0.0890, 0.1758, 0.2215, 0.4475, 0.3044, 0.0163,\n",
       "        0.0146, 0.0327, 0.0654, 0.3431, 0.0064, 0.0179, 0.0116, 0.0558, 0.4317,\n",
       "        0.1594, 0.3265, 0.3046], device='cuda:0', grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrain_vae(test_data)[0][samp, :D]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1185, device='cuda:0', grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.abs(test_data[samp,:D] - pretrain_vae(test_data)[0][samp, :D]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1146, device='cuda:0', grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrain_vae(test_data)[1][:, :D].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6333, device='cuda:0', grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.exp(pretrain_vae(test_data)[2][:, :D]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VAE(\n",
       "  (encoder): Sequential(\n",
       "    (0): Linear(in_features=60, out_features=100, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "  )\n",
       "  (enc_mean): Linear(in_features=100, out_features=20, bias=True)\n",
       "  (enc_logvar): Linear(in_features=100, out_features=20, bias=True)\n",
       "  (decoder): Sequential(\n",
       "    (0): Linear(in_features=20, out_features=100, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): Linear(in_features=100, out_features=60, bias=True)\n",
       "    (3): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrain_vae.requires_grad_(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks pretty good.\n",
    "\n",
    "**Gumbel matching pretrained VAE next**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's see how it does here\n",
    "vae_gumbel_with_pre = VAE_Gumbel(2*D, 100, 20, k = 3*z_size)\n",
    "vae_gumbel_with_pre.to(device)\n",
    "vae_gumbel_with_pre_optimizer = torch.optim.Adam(vae_gumbel_with_pre.parameters(), \n",
    "                                                lr=lr, \n",
    "                                                betas = (b1,b2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/4000 (0%)]\tLoss: 168.219208\n",
      "Train Epoch: 1 [1280/4000 (32%)]\tLoss: 155.237366\n",
      "Train Epoch: 1 [2560/4000 (64%)]\tLoss: 161.268143\n",
      "Train Epoch: 1 [3840/4000 (96%)]\tLoss: 151.776031\n",
      "====> Epoch: 1 Average loss: 159.1431\n",
      "====> Test set loss: 40.1893\n",
      "Train Epoch: 2 [0/4000 (0%)]\tLoss: 152.251297\n",
      "Train Epoch: 2 [1280/4000 (32%)]\tLoss: 144.919861\n",
      "Train Epoch: 2 [2560/4000 (64%)]\tLoss: 142.172165\n",
      "Train Epoch: 2 [3840/4000 (96%)]\tLoss: 141.516525\n",
      "====> Epoch: 2 Average loss: 146.5750\n",
      "====> Test set loss: 38.8166\n",
      "Train Epoch: 3 [0/4000 (0%)]\tLoss: 136.122559\n",
      "Train Epoch: 3 [1280/4000 (32%)]\tLoss: 134.785812\n",
      "Train Epoch: 3 [2560/4000 (64%)]\tLoss: 128.904449\n",
      "Train Epoch: 3 [3840/4000 (96%)]\tLoss: 128.727493\n",
      "====> Epoch: 3 Average loss: 132.7747\n",
      "====> Test set loss: 37.5193\n",
      "Train Epoch: 4 [0/4000 (0%)]\tLoss: 126.363541\n",
      "Train Epoch: 4 [1280/4000 (32%)]\tLoss: 121.623680\n",
      "Train Epoch: 4 [2560/4000 (64%)]\tLoss: 123.583015\n",
      "Train Epoch: 4 [3840/4000 (96%)]\tLoss: 113.317459\n",
      "====> Epoch: 4 Average loss: 117.9632\n",
      "====> Test set loss: 36.1340\n",
      "Train Epoch: 5 [0/4000 (0%)]\tLoss: 121.019653\n",
      "Train Epoch: 5 [1280/4000 (32%)]\tLoss: 107.843552\n",
      "Train Epoch: 5 [2560/4000 (64%)]\tLoss: 123.255981\n",
      "Train Epoch: 5 [3840/4000 (96%)]\tLoss: 104.062881\n",
      "====> Epoch: 5 Average loss: 105.9535\n",
      "====> Test set loss: 35.0383\n",
      "Train Epoch: 6 [0/4000 (0%)]\tLoss: 114.577972\n",
      "Train Epoch: 6 [1280/4000 (32%)]\tLoss: 95.154144\n",
      "Train Epoch: 6 [2560/4000 (64%)]\tLoss: 99.411957\n",
      "Train Epoch: 6 [3840/4000 (96%)]\tLoss: 99.447037\n",
      "====> Epoch: 6 Average loss: 99.0487\n",
      "====> Test set loss: 34.3768\n",
      "Train Epoch: 7 [0/4000 (0%)]\tLoss: 89.848465\n",
      "Train Epoch: 7 [1280/4000 (32%)]\tLoss: 111.464226\n",
      "Train Epoch: 7 [2560/4000 (64%)]\tLoss: 94.847122\n",
      "Train Epoch: 7 [3840/4000 (96%)]\tLoss: 95.422577\n",
      "====> Epoch: 7 Average loss: 95.4422\n",
      "====> Test set loss: 33.9716\n",
      "Train Epoch: 8 [0/4000 (0%)]\tLoss: 87.155228\n",
      "Train Epoch: 8 [1280/4000 (32%)]\tLoss: 92.844788\n",
      "Train Epoch: 8 [2560/4000 (64%)]\tLoss: 86.939278\n",
      "Train Epoch: 8 [3840/4000 (96%)]\tLoss: 91.029350\n",
      "====> Epoch: 8 Average loss: 92.9987\n",
      "====> Test set loss: 33.7032\n",
      "Train Epoch: 9 [0/4000 (0%)]\tLoss: 89.398148\n",
      "Train Epoch: 9 [1280/4000 (32%)]\tLoss: 86.722351\n",
      "Train Epoch: 9 [2560/4000 (64%)]\tLoss: 91.572197\n",
      "Train Epoch: 9 [3840/4000 (96%)]\tLoss: 88.299957\n",
      "====> Epoch: 9 Average loss: 91.0074\n",
      "====> Test set loss: 33.5734\n",
      "Train Epoch: 10 [0/4000 (0%)]\tLoss: 96.911133\n",
      "Train Epoch: 10 [1280/4000 (32%)]\tLoss: 89.618439\n",
      "Train Epoch: 10 [2560/4000 (64%)]\tLoss: 89.151108\n",
      "Train Epoch: 10 [3840/4000 (96%)]\tLoss: 84.685150\n",
      "====> Epoch: 10 Average loss: 88.9941\n",
      "====> Test set loss: 33.3807\n",
      "Train Epoch: 11 [0/4000 (0%)]\tLoss: 87.407524\n",
      "Train Epoch: 11 [1280/4000 (32%)]\tLoss: 83.084793\n",
      "Train Epoch: 11 [2560/4000 (64%)]\tLoss: 86.310333\n",
      "Train Epoch: 11 [3840/4000 (96%)]\tLoss: 92.341049\n",
      "====> Epoch: 11 Average loss: 86.4106\n",
      "====> Test set loss: 33.3167\n",
      "Train Epoch: 12 [0/4000 (0%)]\tLoss: 77.887817\n",
      "Train Epoch: 12 [1280/4000 (32%)]\tLoss: 82.757957\n",
      "Train Epoch: 12 [2560/4000 (64%)]\tLoss: 90.265335\n",
      "Train Epoch: 12 [3840/4000 (96%)]\tLoss: 82.165962\n",
      "====> Epoch: 12 Average loss: 84.0156\n",
      "====> Test set loss: 33.2105\n",
      "Train Epoch: 13 [0/4000 (0%)]\tLoss: 88.581284\n",
      "Train Epoch: 13 [1280/4000 (32%)]\tLoss: 73.996948\n",
      "Train Epoch: 13 [2560/4000 (64%)]\tLoss: 84.734604\n",
      "Train Epoch: 13 [3840/4000 (96%)]\tLoss: 78.094383\n",
      "====> Epoch: 13 Average loss: 81.8932\n",
      "====> Test set loss: 33.1282\n",
      "Train Epoch: 14 [0/4000 (0%)]\tLoss: 82.695076\n",
      "Train Epoch: 14 [1280/4000 (32%)]\tLoss: 86.498657\n",
      "Train Epoch: 14 [2560/4000 (64%)]\tLoss: 82.759003\n",
      "Train Epoch: 14 [3840/4000 (96%)]\tLoss: 86.016747\n",
      "====> Epoch: 14 Average loss: 79.5680\n",
      "====> Test set loss: 33.0361\n",
      "Train Epoch: 15 [0/4000 (0%)]\tLoss: 78.468712\n",
      "Train Epoch: 15 [1280/4000 (32%)]\tLoss: 78.981781\n",
      "Train Epoch: 15 [2560/4000 (64%)]\tLoss: 77.727676\n",
      "Train Epoch: 15 [3840/4000 (96%)]\tLoss: 70.248566\n",
      "====> Epoch: 15 Average loss: 77.2533\n",
      "====> Test set loss: 32.9863\n",
      "Train Epoch: 16 [0/4000 (0%)]\tLoss: 74.263962\n",
      "Train Epoch: 16 [1280/4000 (32%)]\tLoss: 66.740082\n",
      "Train Epoch: 16 [2560/4000 (64%)]\tLoss: 74.401947\n",
      "Train Epoch: 16 [3840/4000 (96%)]\tLoss: 68.693985\n",
      "====> Epoch: 16 Average loss: 74.3475\n",
      "====> Test set loss: 32.8832\n",
      "Train Epoch: 17 [0/4000 (0%)]\tLoss: 70.960022\n",
      "Train Epoch: 17 [1280/4000 (32%)]\tLoss: 74.927437\n",
      "Train Epoch: 17 [2560/4000 (64%)]\tLoss: 75.482315\n",
      "Train Epoch: 17 [3840/4000 (96%)]\tLoss: 79.317703\n",
      "====> Epoch: 17 Average loss: 73.3143\n",
      "====> Test set loss: 32.8984\n",
      "Train Epoch: 18 [0/4000 (0%)]\tLoss: 64.642952\n",
      "Train Epoch: 18 [1280/4000 (32%)]\tLoss: 65.832809\n",
      "Train Epoch: 18 [2560/4000 (64%)]\tLoss: 75.723076\n",
      "Train Epoch: 18 [3840/4000 (96%)]\tLoss: 74.250679\n",
      "====> Epoch: 18 Average loss: 70.8904\n",
      "====> Test set loss: 32.8295\n",
      "Train Epoch: 19 [0/4000 (0%)]\tLoss: 75.068069\n",
      "Train Epoch: 19 [1280/4000 (32%)]\tLoss: 67.959747\n",
      "Train Epoch: 19 [2560/4000 (64%)]\tLoss: 72.543663\n",
      "Train Epoch: 19 [3840/4000 (96%)]\tLoss: 64.080811\n",
      "====> Epoch: 19 Average loss: 69.3268\n",
      "====> Test set loss: 32.7610\n",
      "Train Epoch: 20 [0/4000 (0%)]\tLoss: 68.318184\n",
      "Train Epoch: 20 [1280/4000 (32%)]\tLoss: 62.193756\n",
      "Train Epoch: 20 [2560/4000 (64%)]\tLoss: 65.998901\n",
      "Train Epoch: 20 [3840/4000 (96%)]\tLoss: 65.908470\n",
      "====> Epoch: 20 Average loss: 68.6446\n",
      "====> Test set loss: 32.7206\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, n_epochs + 1):\n",
    "    train_pre_trained(train_data, vae_gumbel_with_pre, vae_gumbel_with_pre_optimizer, \n",
    "                      epoch, pretrain_vae, batch_size)\n",
    "    test(test_data, vae_gumbel_with_pre, epoch, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss\n",
      "tensor(0.5389, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    print(\"Test Loss\")\n",
    "    print(F.binary_cross_entropy(vae_gumbel_with_pre(test_data)[0], test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0978, 0.3031, 0.1394, 0.2099, 0.2063, 0.2098, 0.1076, 0.2316, 0.0298,\n",
       "        0.1968, 0.0261, 0.0561, 0.0848, 0.2727, 0.2320, 0.3355, 0.2739, 0.0056,\n",
       "        0.0301, 0.0953, 0.0889, 0.2483, 0.0063, 0.0231, 0.0009, 0.0924, 0.4782,\n",
       "        0.3251, 0.2092, 0.2881], device='cuda:0')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.mean(dim = 0)[:D]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1024, 0.3140, 0.1501, 0.2163, 0.2175, 0.2214, 0.1102, 0.2434, 0.0483,\n",
       "        0.2128, 0.0389, 0.0598, 0.1022, 0.2799, 0.2342, 0.3367, 0.2845, 0.0300,\n",
       "        0.0439, 0.1068, 0.0917, 0.2642, 0.0256, 0.0395, 0.0286, 0.0950, 0.4727,\n",
       "        0.3332, 0.2241, 0.2972], device='cuda:0', grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae_gumbel_with_pre(test_data)[0].mean(dim = 0)[:D]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deviations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1913, 0.2338, 0.2076, 0.2199, 0.2306, 0.1890, 0.1805, 0.1945, 0.1051,\n",
       "        0.2321, 0.0976, 0.1389, 0.1652, 0.1922, 0.2341, 0.2330, 0.2048, 0.0390,\n",
       "        0.0929, 0.1692, 0.1755, 0.2236, 0.0499, 0.0923, 0.0152, 0.1863, 0.1593,\n",
       "        0.2244, 0.2096, 0.2350], device='cuda:0')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.std(dim = 0)[:D]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0489, 0.0382, 0.0722, 0.0661, 0.0476, 0.0494, 0.0542, 0.0756, 0.0369,\n",
       "        0.0635, 0.0307, 0.0383, 0.0466, 0.0789, 0.0941, 0.1072, 0.0429, 0.0276,\n",
       "        0.0320, 0.0490, 0.0490, 0.0699, 0.0238, 0.0289, 0.0273, 0.0518, 0.0419,\n",
       "        0.0966, 0.0474, 0.0831], device='cuda:0', grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae_gumbel_with_pre(test_data)[0].std(dim = 0)[:D]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 0.5286, 0.0000, 0.0231, 0.6963, 0.3966, 0.0103, 0.2939, 0.0000,\n",
       "        0.3152, 0.0000, 0.0000, 0.0000, 0.0617, 0.4150, 0.6262, 0.2110, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.6829, 0.0000, 0.0000, 0.0000, 0.0000, 0.3516,\n",
       "        0.0000, 0.6491, 0.4560], device='cuda:0')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[samp,:D]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1260, 0.3472, 0.1572, 0.3154, 0.2828, 0.2629, 0.1789, 0.3836, 0.0970,\n",
       "        0.1962, 0.0766, 0.1059, 0.1447, 0.2776, 0.4030, 0.4705, 0.3816, 0.0574,\n",
       "        0.0718, 0.1282, 0.2241, 0.3744, 0.0557, 0.0664, 0.0492, 0.1468, 0.5124,\n",
       "        0.2305, 0.2370, 0.2446], device='cuda:0', grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae_gumbel_with_pre(test_data)[0][samp, :D]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    w = vae_gumbel_with_pre.weight_creator(test_data[0:2, :])\n",
    "    subset_indices = sample_subset(w, k=3*z_size, t=0.1).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[28, 12,  8, 13, 45, 59, 21, 18, 52, 50, 42, 46,  1, 47, 39],\n",
       "        [35, 55, 34, 38, 50, 11, 30, 17, 26, 41, 33,  3, 40,  4, 19]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# as long as feature index is lesss than 30, then it isn't picking noise\n",
    "torch.argsort(subset_indices, dim = 1, descending = True)[:, :3 * z_size]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Joint Train**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "joint_vanilla_vae = VAE(2*D, 100, 20)\n",
    "joint_vanilla_vae.to(device)\n",
    "\n",
    "joint_vae_gumbel = VAE_Gumbel(2*D, 100, 20, k = 3*z_size)\n",
    "joint_vae_gumbel.to(device)\n",
    "\n",
    "joint_optimizer = torch.optim.Adam(list(joint_vanilla_vae.parameters()) + list(joint_vae_gumbel.parameters()), \n",
    "                                                lr=lr, \n",
    "                                                betas = (b1,b2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/4000 (0%)]\tLoss: 86.848480\n",
      "Train Epoch: 1 [1280/4000 (32%)]\tLoss: 84.275276\n",
      "Train Epoch: 1 [2560/4000 (64%)]\tLoss: 82.845856\n",
      "Train Epoch: 1 [3840/4000 (96%)]\tLoss: 81.747147\n",
      "====> Epoch: 1 Average loss: 83.7655\n",
      "====> Test set loss: 106.0535\n",
      "Train Epoch: 2 [0/4000 (0%)]\tLoss: 81.726105\n",
      "Train Epoch: 2 [1280/4000 (32%)]\tLoss: 80.686974\n",
      "Train Epoch: 2 [2560/4000 (64%)]\tLoss: 79.847923\n",
      "Train Epoch: 2 [3840/4000 (96%)]\tLoss: 78.858322\n",
      "====> Epoch: 2 Average loss: 80.2634\n",
      "====> Test set loss: 96.4168\n",
      "Train Epoch: 3 [0/4000 (0%)]\tLoss: 78.898964\n",
      "Train Epoch: 3 [1280/4000 (32%)]\tLoss: 77.950134\n",
      "Train Epoch: 3 [2560/4000 (64%)]\tLoss: 77.212387\n",
      "Train Epoch: 3 [3840/4000 (96%)]\tLoss: 76.307381\n",
      "====> Epoch: 3 Average loss: 77.5121\n",
      "====> Test set loss: 90.1183\n",
      "Train Epoch: 4 [0/4000 (0%)]\tLoss: 76.061302\n",
      "Train Epoch: 4 [1280/4000 (32%)]\tLoss: 75.339722\n",
      "Train Epoch: 4 [2560/4000 (64%)]\tLoss: 74.579987\n",
      "Train Epoch: 4 [3840/4000 (96%)]\tLoss: 73.783607\n",
      "====> Epoch: 4 Average loss: 74.9325\n",
      "====> Test set loss: 84.9218\n",
      "Train Epoch: 5 [0/4000 (0%)]\tLoss: 73.600578\n",
      "Train Epoch: 5 [1280/4000 (32%)]\tLoss: 72.848732\n",
      "Train Epoch: 5 [2560/4000 (64%)]\tLoss: 71.988037\n",
      "Train Epoch: 5 [3840/4000 (96%)]\tLoss: 71.651878\n",
      "====> Epoch: 5 Average loss: 72.5539\n",
      "====> Test set loss: 81.2998\n",
      "Train Epoch: 6 [0/4000 (0%)]\tLoss: 72.001770\n",
      "Train Epoch: 6 [1280/4000 (32%)]\tLoss: 71.080666\n",
      "Train Epoch: 6 [2560/4000 (64%)]\tLoss: 70.471008\n",
      "Train Epoch: 6 [3840/4000 (96%)]\tLoss: 69.611885\n",
      "====> Epoch: 6 Average loss: 70.6304\n",
      "====> Test set loss: 80.2777\n",
      "Train Epoch: 7 [0/4000 (0%)]\tLoss: 70.088272\n",
      "Train Epoch: 7 [1280/4000 (32%)]\tLoss: 69.844101\n",
      "Train Epoch: 7 [2560/4000 (64%)]\tLoss: 68.865982\n",
      "Train Epoch: 7 [3840/4000 (96%)]\tLoss: 69.177872\n",
      "====> Epoch: 7 Average loss: 69.2807\n",
      "====> Test set loss: 81.2399\n",
      "Train Epoch: 8 [0/4000 (0%)]\tLoss: 69.222366\n",
      "Train Epoch: 8 [1280/4000 (32%)]\tLoss: 68.629311\n",
      "Train Epoch: 8 [2560/4000 (64%)]\tLoss: 68.070389\n",
      "Train Epoch: 8 [3840/4000 (96%)]\tLoss: 67.895317\n",
      "====> Epoch: 8 Average loss: 68.3794\n",
      "====> Test set loss: 81.4219\n",
      "Train Epoch: 9 [0/4000 (0%)]\tLoss: 67.219070\n",
      "Train Epoch: 9 [1280/4000 (32%)]\tLoss: 67.514862\n",
      "Train Epoch: 9 [2560/4000 (64%)]\tLoss: 68.793320\n",
      "Train Epoch: 9 [3840/4000 (96%)]\tLoss: 67.605515\n",
      "====> Epoch: 9 Average loss: 67.7423\n",
      "====> Test set loss: 82.2546\n",
      "Train Epoch: 10 [0/4000 (0%)]\tLoss: 67.282814\n",
      "Train Epoch: 10 [1280/4000 (32%)]\tLoss: 67.157021\n",
      "Train Epoch: 10 [2560/4000 (64%)]\tLoss: 68.226913\n",
      "Train Epoch: 10 [3840/4000 (96%)]\tLoss: 66.842773\n",
      "====> Epoch: 10 Average loss: 67.3137\n",
      "====> Test set loss: 82.4574\n",
      "Train Epoch: 11 [0/4000 (0%)]\tLoss: 67.695213\n",
      "Train Epoch: 11 [1280/4000 (32%)]\tLoss: 67.036728\n",
      "Train Epoch: 11 [2560/4000 (64%)]\tLoss: 67.299889\n",
      "Train Epoch: 11 [3840/4000 (96%)]\tLoss: 65.958481\n",
      "====> Epoch: 11 Average loss: 66.9961\n",
      "====> Test set loss: 81.8475\n",
      "Train Epoch: 12 [0/4000 (0%)]\tLoss: 67.063637\n",
      "Train Epoch: 12 [1280/4000 (32%)]\tLoss: 67.606339\n",
      "Train Epoch: 12 [2560/4000 (64%)]\tLoss: 66.349533\n",
      "Train Epoch: 12 [3840/4000 (96%)]\tLoss: 65.410179\n",
      "====> Epoch: 12 Average loss: 66.7330\n",
      "====> Test set loss: 80.4987\n",
      "Train Epoch: 13 [0/4000 (0%)]\tLoss: 65.762306\n",
      "Train Epoch: 13 [1280/4000 (32%)]\tLoss: 66.352005\n",
      "Train Epoch: 13 [2560/4000 (64%)]\tLoss: 65.070778\n",
      "Train Epoch: 13 [3840/4000 (96%)]\tLoss: 67.087051\n",
      "====> Epoch: 13 Average loss: 66.5448\n",
      "====> Test set loss: 79.9782\n",
      "Train Epoch: 14 [0/4000 (0%)]\tLoss: 66.419502\n",
      "Train Epoch: 14 [1280/4000 (32%)]\tLoss: 66.219551\n",
      "Train Epoch: 14 [2560/4000 (64%)]\tLoss: 66.950729\n",
      "Train Epoch: 14 [3840/4000 (96%)]\tLoss: 65.271767\n",
      "====> Epoch: 14 Average loss: 66.4040\n",
      "====> Test set loss: 78.4945\n",
      "Train Epoch: 15 [0/4000 (0%)]\tLoss: 65.347282\n",
      "Train Epoch: 15 [1280/4000 (32%)]\tLoss: 66.935738\n",
      "Train Epoch: 15 [2560/4000 (64%)]\tLoss: 65.862709\n",
      "Train Epoch: 15 [3840/4000 (96%)]\tLoss: 65.579453\n",
      "====> Epoch: 15 Average loss: 66.2589\n",
      "====> Test set loss: 77.7828\n",
      "Train Epoch: 16 [0/4000 (0%)]\tLoss: 66.066132\n",
      "Train Epoch: 16 [1280/4000 (32%)]\tLoss: 66.279053\n",
      "Train Epoch: 16 [2560/4000 (64%)]\tLoss: 64.887611\n",
      "Train Epoch: 16 [3840/4000 (96%)]\tLoss: 66.347336\n",
      "====> Epoch: 16 Average loss: 66.1705\n",
      "====> Test set loss: 76.6704\n",
      "Train Epoch: 17 [0/4000 (0%)]\tLoss: 65.713219\n",
      "Train Epoch: 17 [1280/4000 (32%)]\tLoss: 66.854195\n",
      "Train Epoch: 17 [2560/4000 (64%)]\tLoss: 66.327736\n",
      "Train Epoch: 17 [3840/4000 (96%)]\tLoss: 65.423660\n",
      "====> Epoch: 17 Average loss: 66.0924\n",
      "====> Test set loss: 75.7356\n",
      "Train Epoch: 18 [0/4000 (0%)]\tLoss: 66.506882\n",
      "Train Epoch: 18 [1280/4000 (32%)]\tLoss: 65.499237\n",
      "Train Epoch: 18 [2560/4000 (64%)]\tLoss: 65.736557\n",
      "Train Epoch: 18 [3840/4000 (96%)]\tLoss: 65.392570\n",
      "====> Epoch: 18 Average loss: 65.9874\n",
      "====> Test set loss: 75.0423\n",
      "Train Epoch: 19 [0/4000 (0%)]\tLoss: 66.295898\n",
      "Train Epoch: 19 [1280/4000 (32%)]\tLoss: 66.088173\n",
      "Train Epoch: 19 [2560/4000 (64%)]\tLoss: 64.759743\n",
      "Train Epoch: 19 [3840/4000 (96%)]\tLoss: 65.494583\n",
      "====> Epoch: 19 Average loss: 65.9068\n",
      "====> Test set loss: 74.3719\n",
      "Train Epoch: 20 [0/4000 (0%)]\tLoss: 65.826057\n",
      "Train Epoch: 20 [1280/4000 (32%)]\tLoss: 66.397408\n",
      "Train Epoch: 20 [2560/4000 (64%)]\tLoss: 66.540825\n",
      "Train Epoch: 20 [3840/4000 (96%)]\tLoss: 65.697884\n",
      "====> Epoch: 20 Average loss: 65.8637\n",
      "====> Test set loss: 73.4213\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, n_epochs + 1):\n",
    "    train_joint(train_data, joint_vanilla_vae, joint_vae_gumbel, joint_optimizer, epoch, batch_size)\n",
    "    test_joint(test_data, joint_vanilla_vae, joint_vae_gumbel, epoch, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss\n",
      "tensor(0.5452, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    print(\"Test Loss\")\n",
    "    print(F.binary_cross_entropy(joint_vae_gumbel(test_data)[0], test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0978, 0.3031, 0.1394, 0.2099, 0.2063, 0.2098, 0.1076, 0.2316, 0.0298,\n",
       "        0.1968, 0.0261, 0.0561, 0.0848, 0.2727, 0.2320, 0.3355, 0.2739, 0.0056,\n",
       "        0.0301, 0.0953, 0.0889, 0.2483, 0.0063, 0.0231, 0.0009, 0.0924, 0.4782,\n",
       "        0.3251, 0.2092, 0.2881], device='cuda:0')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.mean(dim = 0)[:D]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1078, 0.3124, 0.1577, 0.2222, 0.2225, 0.2211, 0.1145, 0.2420, 0.0653,\n",
       "        0.2137, 0.0455, 0.0678, 0.1044, 0.2837, 0.2368, 0.3319, 0.2860, 0.0432,\n",
       "        0.0580, 0.1193, 0.0988, 0.2575, 0.0338, 0.0576, 0.0425, 0.1012, 0.4774,\n",
       "        0.3368, 0.2207, 0.2978], device='cuda:0', grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joint_vae_gumbel(test_data)[0].mean(dim = 0)[:D]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deviations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1913, 0.2338, 0.2076, 0.2199, 0.2306, 0.1890, 0.1805, 0.1945, 0.1051,\n",
       "        0.2321, 0.0976, 0.1389, 0.1652, 0.1922, 0.2341, 0.2330, 0.2048, 0.0390,\n",
       "        0.0929, 0.1692, 0.1755, 0.2236, 0.0499, 0.0923, 0.0152, 0.1863, 0.1593,\n",
       "        0.2244, 0.2096, 0.2350], device='cuda:0')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.std(dim = 0)[:D]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0452, 0.0416, 0.0576, 0.0502, 0.0535, 0.0399, 0.0450, 0.0479, 0.0390,\n",
       "        0.0504, 0.0335, 0.0421, 0.0419, 0.0363, 0.0495, 0.0332, 0.0363, 0.0307,\n",
       "        0.0351, 0.0520, 0.0463, 0.0400, 0.0276, 0.0389, 0.0311, 0.0454, 0.0236,\n",
       "        0.0383, 0.0481, 0.0447], device='cuda:0', grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joint_vae_gumbel(test_data)[0].std(dim = 0)[:D]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 0.5286, 0.0000, 0.0231, 0.6963, 0.3966, 0.0103, 0.2939, 0.0000,\n",
       "        0.3152, 0.0000, 0.0000, 0.0000, 0.0617, 0.4150, 0.6262, 0.2110, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.6829, 0.0000, 0.0000, 0.0000, 0.0000, 0.3516,\n",
       "        0.0000, 0.6491, 0.4560], device='cuda:0')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[samp,:D]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0701, 0.2890, 0.1689, 0.1704, 0.1435, 0.1886, 0.0755, 0.2708, 0.0325,\n",
       "        0.1740, 0.0354, 0.0469, 0.0618, 0.2541, 0.2209, 0.3065, 0.2965, 0.0297,\n",
       "        0.0269, 0.0873, 0.0863, 0.1973, 0.0103, 0.0357, 0.0260, 0.0666, 0.4750,\n",
       "        0.3386, 0.1913, 0.2646], device='cuda:0', grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joint_vae_gumbel(test_data)[0][samp, :D]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    w = joint_vae_gumbel.weight_creator(test_data[0:2, :])\n",
    "    subset_indices = sample_subset(w, k=3*z_size, t=0.1).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 6, 45,  5, 47, 46,  7, 26, 19, 16, 42,  8, 31, 50, 36,  4],\n",
       "        [45, 28, 15, 31,  3, 18, 27, 35, 48, 19, 52,  0, 43,  9, 20]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argsort(subset_indices, dim = 1, descending = True)[:, :3 * z_size]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Joint Training while selecting exactly z_size. Why does it pick the noise variables?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "joint_vanilla_vae = VAE(2*D, 100, 20)\n",
    "joint_vanilla_vae.to(device)\n",
    "\n",
    "joint_vae_gumbel = VAE_Gumbel(2*D, 100, 20, k = z_size)\n",
    "joint_vae_gumbel.to(device)\n",
    "\n",
    "joint_optimizer = torch.optim.Adam(list(joint_vanilla_vae.parameters()) + list(joint_vae_gumbel.parameters()), \n",
    "                                                lr=lr, \n",
    "                                                betas = (b1,b2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/4000 (0%)]\tLoss: 85.054405\n",
      "Train Epoch: 1 [1280/4000 (32%)]\tLoss: 83.330345\n",
      "Train Epoch: 1 [2560/4000 (64%)]\tLoss: 82.286453\n",
      "Train Epoch: 1 [3840/4000 (96%)]\tLoss: 81.242546\n",
      "====> Epoch: 1 Average loss: 82.9093\n",
      "====> Test set loss: 97.6358\n",
      "Train Epoch: 2 [0/4000 (0%)]\tLoss: 81.174263\n",
      "Train Epoch: 2 [1280/4000 (32%)]\tLoss: 80.213066\n",
      "Train Epoch: 2 [2560/4000 (64%)]\tLoss: 79.237938\n",
      "Train Epoch: 2 [3840/4000 (96%)]\tLoss: 78.435249\n",
      "====> Epoch: 2 Average loss: 79.7377\n",
      "====> Test set loss: 90.1511\n",
      "Train Epoch: 3 [0/4000 (0%)]\tLoss: 78.242432\n",
      "Train Epoch: 3 [1280/4000 (32%)]\tLoss: 77.535652\n",
      "Train Epoch: 3 [2560/4000 (64%)]\tLoss: 76.462410\n",
      "Train Epoch: 3 [3840/4000 (96%)]\tLoss: 75.758675\n",
      "====> Epoch: 3 Average loss: 76.9780\n",
      "====> Test set loss: 84.4369\n",
      "Train Epoch: 4 [0/4000 (0%)]\tLoss: 75.658134\n",
      "Train Epoch: 4 [1280/4000 (32%)]\tLoss: 74.409744\n",
      "Train Epoch: 4 [2560/4000 (64%)]\tLoss: 73.804512\n",
      "Train Epoch: 4 [3840/4000 (96%)]\tLoss: 73.436516\n",
      "====> Epoch: 4 Average loss: 74.3653\n",
      "====> Test set loss: 80.1249\n",
      "Train Epoch: 5 [0/4000 (0%)]\tLoss: 73.001938\n",
      "Train Epoch: 5 [1280/4000 (32%)]\tLoss: 72.321121\n",
      "Train Epoch: 5 [2560/4000 (64%)]\tLoss: 71.671204\n",
      "Train Epoch: 5 [3840/4000 (96%)]\tLoss: 70.518066\n",
      "====> Epoch: 5 Average loss: 72.0869\n",
      "====> Test set loss: 76.8887\n",
      "Train Epoch: 6 [0/4000 (0%)]\tLoss: 71.511497\n",
      "Train Epoch: 6 [1280/4000 (32%)]\tLoss: 70.557800\n",
      "Train Epoch: 6 [2560/4000 (64%)]\tLoss: 70.255165\n",
      "Train Epoch: 6 [3840/4000 (96%)]\tLoss: 69.506134\n",
      "====> Epoch: 6 Average loss: 70.3692\n",
      "====> Test set loss: 75.9245\n",
      "Train Epoch: 7 [0/4000 (0%)]\tLoss: 69.161613\n",
      "Train Epoch: 7 [1280/4000 (32%)]\tLoss: 69.362076\n",
      "Train Epoch: 7 [2560/4000 (64%)]\tLoss: 68.417519\n",
      "Train Epoch: 7 [3840/4000 (96%)]\tLoss: 68.562515\n",
      "====> Epoch: 7 Average loss: 69.0544\n",
      "====> Test set loss: 76.1194\n",
      "Train Epoch: 8 [0/4000 (0%)]\tLoss: 68.841576\n",
      "Train Epoch: 8 [1280/4000 (32%)]\tLoss: 68.105606\n",
      "Train Epoch: 8 [2560/4000 (64%)]\tLoss: 68.260986\n",
      "Train Epoch: 8 [3840/4000 (96%)]\tLoss: 66.914909\n",
      "====> Epoch: 8 Average loss: 68.1871\n",
      "====> Test set loss: 76.8144\n",
      "Train Epoch: 9 [0/4000 (0%)]\tLoss: 66.900124\n",
      "Train Epoch: 9 [1280/4000 (32%)]\tLoss: 67.096031\n",
      "Train Epoch: 9 [2560/4000 (64%)]\tLoss: 67.723618\n",
      "Train Epoch: 9 [3840/4000 (96%)]\tLoss: 66.863815\n",
      "====> Epoch: 9 Average loss: 67.5841\n",
      "====> Test set loss: 76.5656\n",
      "Train Epoch: 10 [0/4000 (0%)]\tLoss: 67.381538\n",
      "Train Epoch: 10 [1280/4000 (32%)]\tLoss: 67.131310\n",
      "Train Epoch: 10 [2560/4000 (64%)]\tLoss: 66.572609\n",
      "Train Epoch: 10 [3840/4000 (96%)]\tLoss: 67.496544\n",
      "====> Epoch: 10 Average loss: 67.1307\n",
      "====> Test set loss: 76.2214\n",
      "Train Epoch: 11 [0/4000 (0%)]\tLoss: 67.650871\n",
      "Train Epoch: 11 [1280/4000 (32%)]\tLoss: 66.728012\n",
      "Train Epoch: 11 [2560/4000 (64%)]\tLoss: 66.405167\n",
      "Train Epoch: 11 [3840/4000 (96%)]\tLoss: 66.475075\n",
      "====> Epoch: 11 Average loss: 66.8618\n",
      "====> Test set loss: 76.0897\n",
      "Train Epoch: 12 [0/4000 (0%)]\tLoss: 67.104019\n",
      "Train Epoch: 12 [1280/4000 (32%)]\tLoss: 66.547707\n",
      "Train Epoch: 12 [2560/4000 (64%)]\tLoss: 66.518517\n",
      "Train Epoch: 12 [3840/4000 (96%)]\tLoss: 65.798126\n",
      "====> Epoch: 12 Average loss: 66.5932\n",
      "====> Test set loss: 74.8316\n",
      "Train Epoch: 13 [0/4000 (0%)]\tLoss: 66.586899\n",
      "Train Epoch: 13 [1280/4000 (32%)]\tLoss: 66.887497\n",
      "Train Epoch: 13 [2560/4000 (64%)]\tLoss: 66.915337\n",
      "Train Epoch: 13 [3840/4000 (96%)]\tLoss: 65.954910\n",
      "====> Epoch: 13 Average loss: 66.3960\n",
      "====> Test set loss: 73.9316\n",
      "Train Epoch: 14 [0/4000 (0%)]\tLoss: 65.937576\n",
      "Train Epoch: 14 [1280/4000 (32%)]\tLoss: 66.952965\n",
      "Train Epoch: 14 [2560/4000 (64%)]\tLoss: 66.059532\n",
      "Train Epoch: 14 [3840/4000 (96%)]\tLoss: 66.444000\n",
      "====> Epoch: 14 Average loss: 66.2594\n",
      "====> Test set loss: 73.3609\n",
      "Train Epoch: 15 [0/4000 (0%)]\tLoss: 66.089500\n",
      "Train Epoch: 15 [1280/4000 (32%)]\tLoss: 65.768318\n",
      "Train Epoch: 15 [2560/4000 (64%)]\tLoss: 66.536316\n",
      "Train Epoch: 15 [3840/4000 (96%)]\tLoss: 65.965714\n",
      "====> Epoch: 15 Average loss: 66.1431\n",
      "====> Test set loss: 72.8876\n",
      "Train Epoch: 16 [0/4000 (0%)]\tLoss: 66.920532\n",
      "Train Epoch: 16 [1280/4000 (32%)]\tLoss: 65.669174\n",
      "Train Epoch: 16 [2560/4000 (64%)]\tLoss: 66.913315\n",
      "Train Epoch: 16 [3840/4000 (96%)]\tLoss: 65.229706\n",
      "====> Epoch: 16 Average loss: 66.0230\n",
      "====> Test set loss: 72.1950\n",
      "Train Epoch: 17 [0/4000 (0%)]\tLoss: 65.723160\n",
      "Train Epoch: 17 [1280/4000 (32%)]\tLoss: 66.050911\n",
      "Train Epoch: 17 [2560/4000 (64%)]\tLoss: 65.900696\n",
      "Train Epoch: 17 [3840/4000 (96%)]\tLoss: 66.078278\n",
      "====> Epoch: 17 Average loss: 65.9425\n",
      "====> Test set loss: 71.1764\n",
      "Train Epoch: 18 [0/4000 (0%)]\tLoss: 65.876816\n",
      "Train Epoch: 18 [1280/4000 (32%)]\tLoss: 65.711258\n",
      "Train Epoch: 18 [2560/4000 (64%)]\tLoss: 65.709244\n",
      "Train Epoch: 18 [3840/4000 (96%)]\tLoss: 65.711220\n",
      "====> Epoch: 18 Average loss: 65.8534\n",
      "====> Test set loss: 70.7656\n",
      "Train Epoch: 19 [0/4000 (0%)]\tLoss: 64.957802\n",
      "Train Epoch: 19 [1280/4000 (32%)]\tLoss: 66.265129\n",
      "Train Epoch: 19 [2560/4000 (64%)]\tLoss: 66.267715\n",
      "Train Epoch: 19 [3840/4000 (96%)]\tLoss: 66.445549\n",
      "====> Epoch: 19 Average loss: 65.8105\n",
      "====> Test set loss: 70.3744\n",
      "Train Epoch: 20 [0/4000 (0%)]\tLoss: 66.267609\n",
      "Train Epoch: 20 [1280/4000 (32%)]\tLoss: 65.636124\n",
      "Train Epoch: 20 [2560/4000 (64%)]\tLoss: 65.811623\n",
      "Train Epoch: 20 [3840/4000 (96%)]\tLoss: 65.308167\n",
      "====> Epoch: 20 Average loss: 65.7116\n",
      "====> Test set loss: 70.0376\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, n_epochs + 1):\n",
    "    train_joint(train_data, joint_vanilla_vae, joint_vae_gumbel, joint_optimizer, epoch, batch_size)\n",
    "    test_joint(test_data, joint_vanilla_vae, joint_vae_gumbel, epoch, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss\n",
      "tensor(0.5454, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    print(\"Test Loss\")\n",
    "    print(F.binary_cross_entropy(joint_vae_gumbel(test_data)[0], test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0978, 0.3031, 0.1394, 0.2099, 0.2063, 0.2098, 0.1076, 0.2316, 0.0298,\n",
       "        0.1968, 0.0261, 0.0561, 0.0848, 0.2727, 0.2320, 0.3355, 0.2739, 0.0056,\n",
       "        0.0301, 0.0953, 0.0889, 0.2483, 0.0063, 0.0231, 0.0009, 0.0924, 0.4782,\n",
       "        0.3251, 0.2092, 0.2881], device='cuda:0')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.mean(dim = 0)[:D]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1080, 0.3095, 0.1499, 0.2192, 0.2195, 0.2185, 0.1156, 0.2413, 0.0600,\n",
       "        0.2146, 0.0606, 0.0694, 0.1076, 0.2810, 0.2337, 0.3362, 0.2855, 0.0416,\n",
       "        0.0580, 0.1115, 0.1001, 0.2579, 0.0355, 0.0471, 0.0343, 0.0980, 0.4774,\n",
       "        0.3319, 0.2198, 0.2976], device='cuda:0', grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joint_vae_gumbel(test_data)[0].mean(dim = 0)[:D]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deviations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1913, 0.2338, 0.2076, 0.2199, 0.2306, 0.1890, 0.1805, 0.1945, 0.1051,\n",
       "        0.2321, 0.0976, 0.1389, 0.1652, 0.1922, 0.2341, 0.2330, 0.2048, 0.0390,\n",
       "        0.0929, 0.1692, 0.1755, 0.2236, 0.0499, 0.0923, 0.0152, 0.1863, 0.1593,\n",
       "        0.2244, 0.2096, 0.2350], device='cuda:0')"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.std(dim = 0)[:D]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0488, 0.0359, 0.0530, 0.0466, 0.0421, 0.0457, 0.0490, 0.0465, 0.0417,\n",
       "        0.0520, 0.0442, 0.0401, 0.0541, 0.0396, 0.0469, 0.0393, 0.0390, 0.0336,\n",
       "        0.0387, 0.0432, 0.0507, 0.0386, 0.0343, 0.0347, 0.0326, 0.0458, 0.0243,\n",
       "        0.0362, 0.0481, 0.0422], device='cuda:0', grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joint_vae_gumbel(test_data)[0].std(dim = 0)[:D]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 0.5286, 0.0000, 0.0231, 0.6963, 0.3966, 0.0103, 0.2939, 0.0000,\n",
       "        0.3152, 0.0000, 0.0000, 0.0000, 0.0617, 0.4150, 0.6262, 0.2110, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.6829, 0.0000, 0.0000, 0.0000, 0.0000, 0.3516,\n",
       "        0.0000, 0.6491, 0.4560], device='cuda:0')"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[samp,:D]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0940, 0.3125, 0.1479, 0.2326, 0.2295, 0.2024, 0.0806, 0.2793, 0.0788,\n",
       "        0.2053, 0.0612, 0.0664, 0.0838, 0.2944, 0.2076, 0.3659, 0.2146, 0.0408,\n",
       "        0.0572, 0.0857, 0.1275, 0.2184, 0.0294, 0.0566, 0.0222, 0.0799, 0.4787,\n",
       "        0.3291, 0.2355, 0.2589], device='cuda:0', grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joint_vae_gumbel(test_data)[0][samp, :D]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    w = joint_vae_gumbel.weight_creator(test_data[0:10, :])\n",
    "    subset_indices = sample_subset(w, k=z_size, t=0.1).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[36, 14, 37, 55, 25],\n",
       "        [15, 26,  2, 54, 55],\n",
       "        [46, 37, 44, 13, 15],\n",
       "        [23, 11, 40, 34, 31],\n",
       "        [53,  6, 49, 21, 20],\n",
       "        [38,  8, 29, 48, 28],\n",
       "        [17, 38, 31,  6, 25],\n",
       "        [ 4, 59, 50, 39, 37],\n",
       "        [ 4, 58, 29, 30, 32],\n",
       "        [17, 16,  4,  9,  7]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argsort(subset_indices, dim = 1, descending = True)[:, :z_size]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matching pre trained is actually better here than joint training.\n",
    "The gumbel trick greatly reduces the ability to make predictions. \n",
    "Notice that the standard deviations are not as high as in the original data. Not being able to use a model looking at the full data as an anchor definitely hurts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculation of Loss only over select features\n",
    "What happens if we limit the calculation of the loss to just the first few non-noisy stuff?\n",
    "\n",
    "Not doing joint training here because the calculation of loss is hidden inside utils and cannot modify the indexing so easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_truncated_with_gradients(df, model, optimizer, epoch, batch_size, Dim):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    permutations = torch.randperm(df.shape[0])\n",
    "    gradients = torch.zeros(df.shape[1]).to(device)\n",
    "    for i in range(math.ceil(len(df)/batch_size)):\n",
    "        batch_ind = permutations[i * batch_size : (i+1) * batch_size]\n",
    "        batch_data = df[batch_ind, :].clone().to(device)\n",
    "        \n",
    "        \n",
    "        # need to do this twice because deriative with respect to input not implemented in BCE\n",
    "        # so need to switch them up\n",
    "        optimizer.zero_grad()\n",
    "        batch_data.requires_grad_(True)\n",
    "        mu_x, mu_latent, logvar_latent = model(batch_data)\n",
    "        # why clone detach here?\n",
    "        # still want gradient with respect to input, but BCE gradient with respect to target is not defined\n",
    "        # plus we only want to see how input affects mu_x, not the target\n",
    "        loss = loss_function_per_autoencoder(batch_data[:, :Dim].clone().detach(), mu_x[:, :Dim], \n",
    "                                             mu_latent, logvar_latent) \n",
    "        loss.backward(retain_graph=True)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            gradients += torch.sqrt(batch_data.grad ** 2).sum(dim = 0)\n",
    "        # no step\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        # do not calculate with respect to \n",
    "        batch_data.requires_grad_(False)\n",
    "        mu_x.requires_grad_(True)\n",
    "        loss = loss_function_per_autoencoder(batch_data[:, :Dim], mu_x[:, :Dim], mu_latent, logvar_latent) \n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "        \n",
    "        if i % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, i * len(batch_data), len(df),\n",
    "                100. * i * len(batch_data)/ len(df),\n",
    "                loss.item() / len(batch_data)))\n",
    "\n",
    "    print('====> Epoch: {} Average loss: {:.4f}'.format(\n",
    "          epoch, train_loss / len(df)))\n",
    "    \n",
    "    return gradients\n",
    "    \n",
    "# match pre trained model\n",
    "def train_pre_trained_truncated(df, model, optimizer, epoch, pretrained_model, batch_size, D):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    permutations = torch.randperm(df.shape[0])\n",
    "    for i in range(math.ceil(len(df)/batch_size)):\n",
    "        batch_ind = permutations[i * batch_size : (i+1) * batch_size]\n",
    "        batch_data = df[batch_ind, :].clone()\n",
    "        \n",
    "        batch_data.requires_grad_(True)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        mu_x, mu_latent, logvar_latent = model(batch_data)\n",
    "        with torch.no_grad():\n",
    "            _, mu_latent_2, logvar_latent_2 = pretrained_model(batch_data)\n",
    "        \n",
    "        loss = loss_function_per_autoencoder(batch_data[:, :D], mu_x[:, :D], mu_latent, logvar_latent)\n",
    "        loss += 10*F.mse_loss(mu_latent, mu_latent_2, reduction = 'sum')\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if i % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, i * len(batch_data), len(df),\n",
    "                100. * i * len(batch_data)/ len(df),\n",
    "                loss.item() / len(batch_data)))\n",
    "\n",
    "    print('====> Epoch: {} Average loss: {:.4f}'.format(\n",
    "          epoch, train_loss / len(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_t = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's see how it does here\n",
    "vae_gumbel_truncated = VAE_Gumbel(2*D, 100, 20, k = 3*z_size, t = global_t)\n",
    "vae_gumbel_truncated.to(device)\n",
    "vae_gumbel_trunc_optimizer = torch.optim.Adam(vae_gumbel_truncated.parameters(), \n",
    "                                                lr=lr, \n",
    "                                                betas = (b1,b2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just train a gumbel without matching or joint training to see"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/4000 (0%)]\tLoss: 21.093872\n",
      "Train Epoch: 1 [1280/4000 (32%)]\tLoss: 20.668814\n",
      "Train Epoch: 1 [2560/4000 (64%)]\tLoss: 20.204716\n",
      "Train Epoch: 1 [3840/4000 (96%)]\tLoss: 19.703491\n",
      "====> Epoch: 1 Average loss: 20.3773\n",
      "====> Test set loss: 40.6477\n",
      "Train Epoch: 2 [0/4000 (0%)]\tLoss: 19.545073\n",
      "Train Epoch: 2 [1280/4000 (32%)]\tLoss: 18.960094\n",
      "Train Epoch: 2 [2560/4000 (64%)]\tLoss: 18.473204\n",
      "Train Epoch: 2 [3840/4000 (96%)]\tLoss: 17.832443\n",
      "====> Epoch: 2 Average loss: 18.8130\n",
      "====> Test set loss: 39.1452\n",
      "Train Epoch: 3 [0/4000 (0%)]\tLoss: 18.011776\n",
      "Train Epoch: 3 [1280/4000 (32%)]\tLoss: 17.209455\n",
      "Train Epoch: 3 [2560/4000 (64%)]\tLoss: 16.648760\n",
      "Train Epoch: 3 [3840/4000 (96%)]\tLoss: 16.204090\n",
      "====> Epoch: 3 Average loss: 17.0178\n",
      "====> Test set loss: 37.2402\n",
      "Train Epoch: 4 [0/4000 (0%)]\tLoss: 15.912292\n",
      "Train Epoch: 4 [1280/4000 (32%)]\tLoss: 15.318943\n",
      "Train Epoch: 4 [2560/4000 (64%)]\tLoss: 14.522866\n",
      "Train Epoch: 4 [3840/4000 (96%)]\tLoss: 14.258093\n",
      "====> Epoch: 4 Average loss: 14.8767\n",
      "====> Test set loss: 35.7664\n",
      "Train Epoch: 5 [0/4000 (0%)]\tLoss: 13.513481\n",
      "Train Epoch: 5 [1280/4000 (32%)]\tLoss: 13.976177\n",
      "Train Epoch: 5 [2560/4000 (64%)]\tLoss: 13.978162\n",
      "Train Epoch: 5 [3840/4000 (96%)]\tLoss: 13.444559\n",
      "====> Epoch: 5 Average loss: 13.6680\n",
      "====> Test set loss: 35.1733\n",
      "Train Epoch: 6 [0/4000 (0%)]\tLoss: 13.590062\n",
      "Train Epoch: 6 [1280/4000 (32%)]\tLoss: 13.026291\n",
      "Train Epoch: 6 [2560/4000 (64%)]\tLoss: 13.427503\n",
      "Train Epoch: 6 [3840/4000 (96%)]\tLoss: 12.770412\n",
      "====> Epoch: 6 Average loss: 13.1988\n",
      "====> Test set loss: 34.8731\n",
      "Train Epoch: 7 [0/4000 (0%)]\tLoss: 12.905790\n",
      "Train Epoch: 7 [1280/4000 (32%)]\tLoss: 12.861897\n",
      "Train Epoch: 7 [2560/4000 (64%)]\tLoss: 12.597086\n",
      "Train Epoch: 7 [3840/4000 (96%)]\tLoss: 12.903750\n",
      "====> Epoch: 7 Average loss: 12.9479\n",
      "====> Test set loss: 34.6820\n",
      "Train Epoch: 8 [0/4000 (0%)]\tLoss: 12.455153\n",
      "Train Epoch: 8 [1280/4000 (32%)]\tLoss: 12.988231\n",
      "Train Epoch: 8 [2560/4000 (64%)]\tLoss: 12.636710\n",
      "Train Epoch: 8 [3840/4000 (96%)]\tLoss: 13.061937\n",
      "====> Epoch: 8 Average loss: 12.7696\n",
      "====> Test set loss: 34.5523\n",
      "Train Epoch: 9 [0/4000 (0%)]\tLoss: 12.620515\n",
      "Train Epoch: 9 [1280/4000 (32%)]\tLoss: 12.653770\n",
      "Train Epoch: 9 [2560/4000 (64%)]\tLoss: 12.442379\n",
      "Train Epoch: 9 [3840/4000 (96%)]\tLoss: 12.367250\n",
      "====> Epoch: 9 Average loss: 12.6719\n",
      "====> Test set loss: 34.4880\n",
      "Train Epoch: 10 [0/4000 (0%)]\tLoss: 12.662868\n",
      "Train Epoch: 10 [1280/4000 (32%)]\tLoss: 12.417583\n",
      "Train Epoch: 10 [2560/4000 (64%)]\tLoss: 12.539018\n",
      "Train Epoch: 10 [3840/4000 (96%)]\tLoss: 12.533263\n",
      "====> Epoch: 10 Average loss: 12.5973\n",
      "====> Test set loss: 34.3257\n",
      "Train Epoch: 11 [0/4000 (0%)]\tLoss: 12.492640\n",
      "Train Epoch: 11 [1280/4000 (32%)]\tLoss: 12.507536\n",
      "Train Epoch: 11 [2560/4000 (64%)]\tLoss: 12.489998\n",
      "Train Epoch: 11 [3840/4000 (96%)]\tLoss: 11.996500\n",
      "====> Epoch: 11 Average loss: 12.5262\n",
      "====> Test set loss: 34.2662\n",
      "Train Epoch: 12 [0/4000 (0%)]\tLoss: 12.663660\n",
      "Train Epoch: 12 [1280/4000 (32%)]\tLoss: 12.617934\n",
      "Train Epoch: 12 [2560/4000 (64%)]\tLoss: 12.260232\n",
      "Train Epoch: 12 [3840/4000 (96%)]\tLoss: 12.184900\n",
      "====> Epoch: 12 Average loss: 12.4886\n",
      "====> Test set loss: 34.2097\n",
      "Train Epoch: 13 [0/4000 (0%)]\tLoss: 12.489765\n",
      "Train Epoch: 13 [1280/4000 (32%)]\tLoss: 12.567298\n",
      "Train Epoch: 13 [2560/4000 (64%)]\tLoss: 12.844160\n",
      "Train Epoch: 13 [3840/4000 (96%)]\tLoss: 12.283421\n",
      "====> Epoch: 13 Average loss: 12.4296\n",
      "====> Test set loss: 34.1992\n",
      "Train Epoch: 14 [0/4000 (0%)]\tLoss: 12.040438\n",
      "Train Epoch: 14 [1280/4000 (32%)]\tLoss: 12.598981\n",
      "Train Epoch: 14 [2560/4000 (64%)]\tLoss: 12.309459\n",
      "Train Epoch: 14 [3840/4000 (96%)]\tLoss: 12.302941\n",
      "====> Epoch: 14 Average loss: 12.3907\n",
      "====> Test set loss: 34.1809\n",
      "Train Epoch: 15 [0/4000 (0%)]\tLoss: 12.228034\n",
      "Train Epoch: 15 [1280/4000 (32%)]\tLoss: 12.403411\n",
      "Train Epoch: 15 [2560/4000 (64%)]\tLoss: 12.494342\n",
      "Train Epoch: 15 [3840/4000 (96%)]\tLoss: 12.241016\n",
      "====> Epoch: 15 Average loss: 12.3638\n",
      "====> Test set loss: 34.1174\n",
      "Train Epoch: 16 [0/4000 (0%)]\tLoss: 12.443842\n",
      "Train Epoch: 16 [1280/4000 (32%)]\tLoss: 12.336994\n",
      "Train Epoch: 16 [2560/4000 (64%)]\tLoss: 12.058770\n",
      "Train Epoch: 16 [3840/4000 (96%)]\tLoss: 12.437241\n",
      "====> Epoch: 16 Average loss: 12.3396\n",
      "====> Test set loss: 34.0913\n",
      "Train Epoch: 17 [0/4000 (0%)]\tLoss: 12.213386\n",
      "Train Epoch: 17 [1280/4000 (32%)]\tLoss: 12.206146\n",
      "Train Epoch: 17 [2560/4000 (64%)]\tLoss: 12.400524\n",
      "Train Epoch: 17 [3840/4000 (96%)]\tLoss: 12.649755\n",
      "====> Epoch: 17 Average loss: 12.2992\n",
      "====> Test set loss: 34.0207\n",
      "Train Epoch: 18 [0/4000 (0%)]\tLoss: 12.705919\n",
      "Train Epoch: 18 [1280/4000 (32%)]\tLoss: 12.730947\n",
      "Train Epoch: 18 [2560/4000 (64%)]\tLoss: 12.317395\n",
      "Train Epoch: 18 [3840/4000 (96%)]\tLoss: 12.544685\n",
      "====> Epoch: 18 Average loss: 12.2620\n",
      "====> Test set loss: 33.9921\n",
      "Train Epoch: 19 [0/4000 (0%)]\tLoss: 12.375976\n",
      "Train Epoch: 19 [1280/4000 (32%)]\tLoss: 12.491112\n",
      "Train Epoch: 19 [2560/4000 (64%)]\tLoss: 12.540988\n",
      "Train Epoch: 19 [3840/4000 (96%)]\tLoss: 12.273898\n",
      "====> Epoch: 19 Average loss: 12.2689\n",
      "====> Test set loss: 33.9918\n",
      "Train Epoch: 20 [0/4000 (0%)]\tLoss: 12.389448\n",
      "Train Epoch: 20 [1280/4000 (32%)]\tLoss: 12.353893\n",
      "Train Epoch: 20 [2560/4000 (64%)]\tLoss: 12.198627\n",
      "Train Epoch: 20 [3840/4000 (96%)]\tLoss: 12.307508\n",
      "====> Epoch: 20 Average loss: 12.2464\n",
      "====> Test set loss: 33.9931\n"
     ]
    }
   ],
   "source": [
    "gradients = torch.zeros(train_data.shape[1]).to(device)\n",
    "for epoch in range(1, n_epochs+1):\n",
    "    grads=train_truncated_with_gradients(train_data, vae_gumbel_truncated, \n",
    "                                         vae_gumbel_trunc_optimizer, epoch, batch_size, Dim = D)\n",
    "    if epoch > 5:\n",
    "        gradients += grads\n",
    "    test(test_data, vae_gumbel_truncated, epoch, batch_size)\n",
    "    \n",
    "gradients = gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fe76423e290>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(gradients.clone().detach().cpu().numpy()[:, np.newaxis])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0978, 0.3031, 0.1394, 0.2099, 0.2063, 0.2098, 0.1076, 0.2316, 0.0298,\n",
       "        0.1968, 0.0261, 0.0561, 0.0848, 0.2727, 0.2320, 0.3355, 0.2739, 0.0056,\n",
       "        0.0301, 0.0953, 0.0889, 0.2483, 0.0063, 0.0231, 0.0009, 0.0924, 0.4782,\n",
       "        0.3251, 0.2092, 0.2881], device='cuda:0')"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.mean(dim = 0)[:D]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1148, 0.3103, 0.1607, 0.2130, 0.2203, 0.2164, 0.1107, 0.2323, 0.0488,\n",
       "        0.2214, 0.0400, 0.0656, 0.1128, 0.2947, 0.2303, 0.3229, 0.2823, 0.0309,\n",
       "        0.0529, 0.1148, 0.0933, 0.2548, 0.0326, 0.0445, 0.0233, 0.0937, 0.4761,\n",
       "        0.3437, 0.2285, 0.3099], device='cuda:0', grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae_gumbel_truncated(test_data)[0].mean(dim = 0)[:D]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1913, 0.2338, 0.2076, 0.2199, 0.2306, 0.1890, 0.1805, 0.1945, 0.1051,\n",
       "        0.2321, 0.0976, 0.1389, 0.1652, 0.1922, 0.2341, 0.2330, 0.2048, 0.0390,\n",
       "        0.0929, 0.1692, 0.1755, 0.2236, 0.0499, 0.0923, 0.0152, 0.1863, 0.1593,\n",
       "        0.2244, 0.2096, 0.2350], device='cuda:0')"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.std(dim = 0)[:D]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0556, 0.0347, 0.0505, 0.0569, 0.0638, 0.0486, 0.0499, 0.0591, 0.0438,\n",
       "        0.0514, 0.0384, 0.0493, 0.0548, 0.0377, 0.0710, 0.0368, 0.0384, 0.0319,\n",
       "        0.0425, 0.0477, 0.0551, 0.0525, 0.0342, 0.0383, 0.0272, 0.0547, 0.0251,\n",
       "        0.0359, 0.0535, 0.0358], device='cuda:0', grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae_gumbel_truncated(test_data)[0].std(dim = 0)[:D]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    w = vae_gumbel_truncated.weight_creator(test_data[0:10, :])\n",
    "    subset_indices = sample_subset(w, k=3*z_size, t=global_t).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fe76417aa50>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(subset_indices.sum(dim = 0).clone().detach().cpu().numpy()[:, np.newaxis])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[7.8803e-09, 1.4471e-04, 5.5669e-03, 6.0727e-01, 4.1324e-12, 7.9017e-11,\n",
       "         2.1042e-10, 2.8982e-07, 5.7122e-11, 6.2353e-12, 8.7536e-06, 1.2823e-11,\n",
       "         3.1752e-02, 8.8964e-03, 1.2161e-08, 3.3722e-10, 8.6845e-05, 3.6338e-05,\n",
       "         1.5179e-05, 5.8932e-02, 4.9361e-03, 2.2064e-09, 2.8243e-16, 7.3968e-08,\n",
       "         2.0032e-09, 1.0720e-07, 2.3200e-08, 1.5558e+00, 3.9544e-02, 1.1767e+00,\n",
       "         2.7878e-02, 1.1934e+00, 3.5791e-03, 1.3557e+00, 1.0642e+00, 9.5752e-01,\n",
       "         1.1614e+00, 1.2978e-03, 1.0829e+00, 5.3039e-02, 3.0662e-01, 6.2086e-01,\n",
       "         6.0323e-09, 1.9525e-03, 2.4324e-25, 5.1195e-01, 5.8341e-06, 9.7766e-01,\n",
       "         1.7341e-07, 5.5809e-13, 1.3543e-10, 1.6737e+00, 1.6442e-14, 1.6899e-05,\n",
       "         1.1059e-09, 2.0334e-01, 1.2238e-01, 2.3391e-04, 1.9057e-01, 3.1766e-06],\n",
       "        [2.5827e-04, 1.8095e-06, 1.4449e-10, 1.6598e-09, 1.3464e-22, 5.2488e-13,\n",
       "         2.0511e-05, 6.1863e-14, 2.8131e-11, 5.5801e-07, 3.2731e-09, 7.6450e-13,\n",
       "         1.3932e-21, 9.9730e-01, 9.9782e-09, 3.5134e-01, 2.4753e-06, 3.9091e-07,\n",
       "         5.2938e-04, 6.5182e-27, 2.8585e-14, 1.8811e-04, 1.0694e-08, 2.3071e-13,\n",
       "         2.6172e-06, 1.0108e-15, 7.1548e-02, 7.0653e-01, 1.0190e-06, 1.4724e+00,\n",
       "         1.2625e-13, 3.7025e-01, 8.4269e-01, 4.0852e-01, 1.0087e+00, 1.4050e+00,\n",
       "         5.2639e-01, 9.3101e-05, 1.6639e+00, 1.6410e-04, 5.7916e-01, 1.0455e-06,\n",
       "         9.2076e-08, 4.8124e-12, 1.3526e+00, 2.0402e-06, 1.1172e-13, 1.8045e+00,\n",
       "         1.5382e-10, 2.8147e-07, 7.4384e-09, 8.6323e-01, 4.4462e-26, 3.1312e-09,\n",
       "         2.4104e-20, 2.7503e-01, 4.3214e-08, 1.2428e-13, 2.9964e-01, 9.4145e-09],\n",
       "        [7.5076e-13, 3.4852e-08, 4.2651e-10, 1.7310e-07, 3.2619e-10, 4.0973e-04,\n",
       "         8.5583e-06, 1.2969e-10, 1.0740e-06, 2.2085e-15, 2.9688e-15, 2.3249e-23,\n",
       "         6.1272e-08, 1.5779e+00, 3.1847e-09, 1.9003e-09, 2.1294e-03, 9.5075e-08,\n",
       "         2.2150e-05, 4.6736e-09, 3.8811e-27, 1.0640e-08, 1.9790e-15, 3.6270e-06,\n",
       "         5.5501e-04, 8.2472e-11, 2.4540e-03, 1.5291e+00, 9.6084e-06, 1.0000e+00,\n",
       "         4.9335e-01, 1.3857e-13, 2.5332e-16, 1.6051e+00, 7.0315e-01, 9.4469e-03,\n",
       "         1.0878e+00, 1.3143e-01, 1.4242e+00, 3.9325e-01, 3.0605e-01, 6.1674e-01,\n",
       "         4.9761e-08, 7.3998e-03, 1.0995e+00, 4.9887e-02, 1.3177e-14, 1.0320e+00,\n",
       "         6.3303e-02, 1.6010e-05, 4.4290e-06, 7.6845e-01, 6.7121e-15, 6.8632e-15,\n",
       "         9.1001e-01, 1.6066e-02, 1.3825e-05, 1.4179e-03, 1.6008e-01, 8.6508e-03],\n",
       "        [2.8379e-11, 9.2607e-08, 3.2263e-21, 9.0789e-08, 9.1474e-06, 9.1071e-06,\n",
       "         1.9303e-25, 3.4214e-07, 1.6232e-10, 1.7857e-07, 9.9071e-19, 6.9353e-04,\n",
       "         5.7387e-05, 1.8925e-01, 1.4586e-11, 1.2467e-13, 9.5963e-14, 8.2191e-10,\n",
       "         2.3820e-06, 4.5831e-04, 2.8008e-08, 3.8421e-01, 1.0508e-06, 1.5516e-08,\n",
       "         1.0492e-04, 5.5905e-10, 4.6554e-01, 7.0581e-01, 5.8389e-15, 5.5948e-01,\n",
       "         1.3628e-06, 7.6274e-01, 7.2504e-09, 1.9330e+00, 3.0815e-06, 1.8194e+00,\n",
       "         1.5083e-06, 1.3965e+00, 1.6508e+00, 2.0143e-27, 9.9199e-01, 9.2538e-03,\n",
       "         7.1834e-20, 2.6015e-13, 1.9527e+00, 3.4592e-06, 2.1885e-23, 1.9569e+00,\n",
       "         3.1993e-05, 3.1114e-05, 1.2287e-04, 4.9142e-09, 8.4527e-13, 2.3786e-07,\n",
       "         3.7466e-08, 1.2048e-04, 6.9552e-11, 1.0212e-09, 2.2082e-01, 6.3424e-19],\n",
       "        [6.1006e-09, 3.9790e-09, 1.1153e-12, 5.6017e-22, 4.4783e-21, 1.2284e-07,\n",
       "         1.5524e-14, 5.3348e-05, 1.4927e-08, 4.3151e-14, 1.1801e-08, 8.5475e-11,\n",
       "         4.2892e-07, 1.5839e+00, 1.5518e-13, 4.1415e-14, 2.0755e-12, 3.0525e-08,\n",
       "         5.8996e-11, 8.1946e-10, 5.8438e-09, 5.9066e-14, 5.1053e-11, 1.1438e-09,\n",
       "         2.9766e-07, 2.3811e-04, 2.8913e-01, 2.1738e+00, 1.5424e-11, 6.5107e-01,\n",
       "         1.2209e-01, 1.7981e-02, 2.8051e-01, 1.7743e+00, 2.1123e-01, 9.1023e-01,\n",
       "         1.2627e-12, 8.0388e-01, 2.1115e+00, 6.5842e-06, 7.8077e-01, 3.3832e-01,\n",
       "         6.4900e-19, 3.4475e-13, 4.2619e-01, 1.4840e-07, 5.5414e-04, 9.0251e-01,\n",
       "         3.4252e-20, 3.7541e-05, 8.0601e-07, 6.8303e-05, 1.4225e-18, 4.5683e-05,\n",
       "         5.5544e-08, 4.7403e-04, 4.0232e-08, 1.3044e-13, 1.6211e+00, 1.1780e-13],\n",
       "        [7.5988e-14, 1.0758e-13, 9.9151e-11, 8.6580e-14, 5.4830e-07, 1.6820e-10,\n",
       "         1.9260e-08, 9.0773e-11, 9.2741e-06, 7.3174e-08, 2.0443e-03, 1.5912e-08,\n",
       "         8.5389e-20, 7.2897e-01, 2.1920e-02, 1.0227e-01, 1.4272e-05, 8.4168e-19,\n",
       "         3.7844e-10, 1.0954e-11, 3.2811e-13, 3.6469e-09, 7.4475e-25, 2.7801e-05,\n",
       "         6.6463e-15, 2.3164e-12, 6.2384e-01, 1.3000e+00, 9.2069e-28, 1.2673e+00,\n",
       "         8.6278e-01, 4.6753e-01, 6.4410e-01, 1.0580e-03, 4.3556e-03, 1.1261e+00,\n",
       "         2.4687e-06, 9.0936e-01, 6.0903e-01, 1.1794e+00, 6.2150e-01, 3.2781e-02,\n",
       "         3.3366e-08, 4.0862e-11, 9.6238e-01, 1.0218e-07, 6.9615e-21, 1.0385e+00,\n",
       "         1.0584e-09, 2.7012e-18, 1.9148e-04, 9.1952e-01, 3.4476e-05, 1.3159e-08,\n",
       "         6.5712e-06, 3.2436e-02, 1.1982e-04, 1.7679e-03, 1.5406e+00, 3.2452e-07],\n",
       "        [9.5078e-17, 4.5179e-15, 1.4524e-04, 3.0030e-06, 3.7068e-01, 4.8954e-01,\n",
       "         2.5124e-04, 2.0728e-05, 1.2265e-01, 4.3660e-02, 1.1894e-16, 1.9450e-03,\n",
       "         6.9322e-02, 1.5892e+00, 7.0130e-10, 3.4478e-06, 6.8016e-19, 6.8678e-10,\n",
       "         1.1364e-01, 3.1313e-03, 6.5782e-12, 2.2023e-01, 1.4079e-08, 1.3112e-14,\n",
       "         5.2225e-10, 7.4594e-07, 1.6521e+00, 1.3468e+00, 1.8328e-02, 7.6180e-01,\n",
       "         7.9794e-04, 3.0763e-02, 1.4614e-04, 1.3652e+00, 1.9824e-07, 5.8209e-02,\n",
       "         5.1610e-01, 5.8083e-14, 1.5226e+00, 1.8837e-01, 4.9744e-01, 4.0629e-02,\n",
       "         1.0593e-09, 1.2197e-01, 3.2075e-02, 3.4463e-01, 6.2764e-05, 4.2014e-05,\n",
       "         3.8111e-06, 8.4931e-10, 2.7609e-04, 7.3488e-01, 1.0530e-01, 3.9202e-08,\n",
       "         1.8092e-10, 1.0457e+00, 1.1814e-09, 1.4541e-09, 1.5912e+00, 6.2332e-07],\n",
       "        [6.5916e-09, 3.1243e-05, 9.3991e-02, 1.1655e-03, 1.7154e-07, 4.5081e-11,\n",
       "         1.6768e-10, 2.8789e-16, 5.1329e-16, 1.1539e-03, 2.5478e-11, 6.0959e-04,\n",
       "         4.1298e-11, 1.4663e+00, 1.0235e-07, 1.3227e-09, 2.5913e-08, 2.0547e-13,\n",
       "         7.3880e-15, 1.8512e-13, 5.5184e-05, 4.5305e-15, 5.4987e-12, 8.6716e-10,\n",
       "         5.1485e-11, 2.0810e-12, 5.2801e-11, 1.7708e+00, 6.9849e-16, 1.6293e+00,\n",
       "         5.0721e-05, 1.5200e-17, 1.1657e+00, 1.4329e+00, 1.2377e+00, 1.6589e+00,\n",
       "         4.7790e-01, 1.2586e-10, 3.4489e-01, 2.5788e-03, 1.5523e-07, 3.0382e-01,\n",
       "         1.5302e-11, 1.1054e-15, 9.1421e-02, 1.6257e-07, 1.2069e-09, 1.4564e+00,\n",
       "         1.1197e-14, 1.2257e-09, 2.8003e-08, 1.6662e+00, 1.5254e-10, 1.5971e-11,\n",
       "         1.3119e-04, 1.9669e-01, 2.1291e-08, 1.1364e-24, 1.4351e-03, 8.1047e-16],\n",
       "        [1.4809e-18, 1.9276e-15, 1.0182e-10, 4.1385e-03, 1.9304e-09, 1.3058e-10,\n",
       "         2.0694e-07, 1.0826e-08, 5.6328e-07, 3.1882e-02, 1.3714e-11, 2.6178e-01,\n",
       "         6.2275e-07, 6.0775e-01, 4.9626e-12, 3.1361e-06, 7.7638e-12, 4.1163e-04,\n",
       "         4.8657e-04, 1.2172e-04, 2.1753e-07, 2.2681e-12, 2.2321e-09, 1.0340e-10,\n",
       "         1.4220e-05, 2.0444e-07, 1.3774e+00, 8.0299e-01, 6.2648e-04, 1.0032e+00,\n",
       "         6.6941e-07, 4.0700e-20, 6.3354e-01, 9.5632e-01, 5.2304e-03, 2.2461e-05,\n",
       "         1.5412e+00, 4.7775e-05, 7.9159e-01, 1.2692e-03, 1.7328e-06, 2.2298e-09,\n",
       "         1.0886e-17, 1.4880e-03, 1.5436e+00, 1.9376e-03, 1.2469e-13, 9.9609e-01,\n",
       "         3.3479e-10, 5.7907e-01, 4.7982e-09, 1.5418e+00, 4.0672e-04, 3.4113e-14,\n",
       "         1.5326e-05, 8.4018e-01, 5.5246e-09, 1.0874e-13, 1.4754e+00, 7.5135e-20],\n",
       "        [2.6541e-10, 7.3998e-29, 1.7854e-04, 1.0831e-13, 7.0473e-08, 2.4118e-09,\n",
       "         1.6595e-12, 1.2912e-17, 6.2881e-13, 2.2805e-01, 2.4273e-06, 9.5804e-05,\n",
       "         4.5228e-07, 1.3194e+00, 7.2472e-07, 8.7274e-14, 1.4416e-08, 9.8645e-06,\n",
       "         1.7101e-02, 1.6118e-08, 3.1194e-03, 1.6186e-08, 4.2684e-03, 2.6395e-06,\n",
       "         3.2882e-06, 4.8243e-14, 1.0811e+00, 8.8167e-06, 1.0397e-05, 1.2778e+00,\n",
       "         9.6227e-02, 2.9787e-04, 1.3627e-01, 1.4500e+00, 1.4370e+00, 1.1676e+00,\n",
       "         4.5417e-08, 3.0172e-01, 5.0813e-01, 3.8220e-01, 5.4361e-01, 1.3595e+00,\n",
       "         3.1469e-03, 1.7982e-06, 1.0732e+00, 1.1528e+00, 1.5662e-06, 1.3208e+00,\n",
       "         7.0016e-12, 2.7084e-14, 7.9304e-05, 5.2467e-06, 5.8771e-06, 3.6980e-18,\n",
       "         7.0360e-11, 2.5192e-03, 1.3385e-01, 4.8249e-16, 3.6806e-06, 6.6552e-10]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[51, 27, 33, 31, 29, 36, 38, 34, 47, 35, 41,  3, 45, 40, 55],\n",
       "        [47, 38, 29, 35, 44, 34, 13, 51, 32, 27, 40, 36, 33, 31, 15],\n",
       "        [33, 13, 27, 38, 44, 36, 47, 29, 54, 51, 34, 41, 30, 39, 40],\n",
       "        [47, 44, 33, 35, 38, 37, 40, 31, 27, 29, 26, 21, 58, 13, 41],\n",
       "        [27, 38, 33, 58, 13, 35, 47, 37, 40, 29, 44, 41, 26, 32, 34],\n",
       "        [58, 27, 29, 39, 35, 47, 44, 51, 37, 30, 13, 32, 26, 40, 38],\n",
       "        [26, 58, 13, 38, 33, 27, 55, 29, 51, 36, 40,  5,  4, 45, 21],\n",
       "        [27, 51, 35, 29, 13, 47, 33, 34, 32, 36, 38, 41, 55,  2, 44],\n",
       "        [44, 51, 36, 58, 26, 29, 47, 33, 55, 27, 38, 32, 13, 49, 11],\n",
       "        [33, 34, 41, 47, 13, 29, 35, 45, 26, 44, 40, 38, 39, 37,  9]])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argsort(subset_indices, dim = 1, descending = True)[:, :3*z_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(42.0417)\n",
      "tensor(107.9584)\n"
     ]
    }
   ],
   "source": [
    "print(subset_indices[:, :D].sum())\n",
    "\n",
    "print(subset_indices[:, D:2*D].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(37, device='cuda:0')"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(w.argsort(descending= True)[:, :3*z_size] < 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happens if you run it on all the data? And not truncate the loss to the first D features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's see how it does here\n",
    "vae_gumbel_truncated = VAE_Gumbel(2*D, 100, 20, k = 3*z_size, t = global_t)\n",
    "vae_gumbel_truncated.to(device)\n",
    "vae_gumbel_trunc_optimizer = torch.optim.Adam(vae_gumbel_truncated.parameters(), \n",
    "                                                lr=lr, \n",
    "                                                betas = (b1,b2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/4000 (0%)]\tLoss: 42.366001\n",
      "Train Epoch: 1 [1280/4000 (32%)]\tLoss: 41.894085\n",
      "Train Epoch: 1 [2560/4000 (64%)]\tLoss: 41.278465\n",
      "Train Epoch: 1 [3840/4000 (96%)]\tLoss: 40.899498\n",
      "====> Epoch: 1 Average loss: 41.5525\n",
      "====> Test set loss: 40.7214\n",
      "Train Epoch: 2 [0/4000 (0%)]\tLoss: 40.682613\n",
      "Train Epoch: 2 [1280/4000 (32%)]\tLoss: 40.277554\n",
      "Train Epoch: 2 [2560/4000 (64%)]\tLoss: 39.740192\n",
      "Train Epoch: 2 [3840/4000 (96%)]\tLoss: 39.320194\n",
      "====> Epoch: 2 Average loss: 39.9941\n",
      "====> Test set loss: 39.2005\n",
      "Train Epoch: 3 [0/4000 (0%)]\tLoss: 39.060650\n",
      "Train Epoch: 3 [1280/4000 (32%)]\tLoss: 38.825985\n",
      "Train Epoch: 3 [2560/4000 (64%)]\tLoss: 38.163338\n",
      "Train Epoch: 3 [3840/4000 (96%)]\tLoss: 37.594349\n",
      "====> Epoch: 3 Average loss: 38.3954\n",
      "====> Test set loss: 37.3983\n",
      "Train Epoch: 4 [0/4000 (0%)]\tLoss: 37.367794\n",
      "Train Epoch: 4 [1280/4000 (32%)]\tLoss: 36.446602\n",
      "Train Epoch: 4 [2560/4000 (64%)]\tLoss: 35.709530\n",
      "Train Epoch: 4 [3840/4000 (96%)]\tLoss: 35.274986\n",
      "====> Epoch: 4 Average loss: 36.3034\n",
      "====> Test set loss: 35.2631\n",
      "Train Epoch: 5 [0/4000 (0%)]\tLoss: 35.190342\n",
      "Train Epoch: 5 [1280/4000 (32%)]\tLoss: 34.834419\n",
      "Train Epoch: 5 [2560/4000 (64%)]\tLoss: 34.673599\n",
      "Train Epoch: 5 [3840/4000 (96%)]\tLoss: 34.366219\n",
      "====> Epoch: 5 Average loss: 34.7454\n",
      "====> Test set loss: 34.3069\n",
      "Train Epoch: 6 [0/4000 (0%)]\tLoss: 34.382404\n",
      "Train Epoch: 6 [1280/4000 (32%)]\tLoss: 34.387878\n",
      "Train Epoch: 6 [2560/4000 (64%)]\tLoss: 34.132675\n",
      "Train Epoch: 6 [3840/4000 (96%)]\tLoss: 34.299274\n",
      "====> Epoch: 6 Average loss: 34.0793\n",
      "====> Test set loss: 33.8935\n",
      "Train Epoch: 7 [0/4000 (0%)]\tLoss: 33.852005\n",
      "Train Epoch: 7 [1280/4000 (32%)]\tLoss: 33.623058\n",
      "Train Epoch: 7 [2560/4000 (64%)]\tLoss: 34.012257\n",
      "Train Epoch: 7 [3840/4000 (96%)]\tLoss: 33.578018\n",
      "====> Epoch: 7 Average loss: 33.7785\n",
      "====> Test set loss: 33.6099\n",
      "Train Epoch: 8 [0/4000 (0%)]\tLoss: 33.792080\n",
      "Train Epoch: 8 [1280/4000 (32%)]\tLoss: 33.675343\n",
      "Train Epoch: 8 [2560/4000 (64%)]\tLoss: 33.775055\n",
      "Train Epoch: 8 [3840/4000 (96%)]\tLoss: 33.746346\n",
      "====> Epoch: 8 Average loss: 33.5829\n",
      "====> Test set loss: 33.4941\n",
      "Train Epoch: 9 [0/4000 (0%)]\tLoss: 33.672237\n",
      "Train Epoch: 9 [1280/4000 (32%)]\tLoss: 33.422089\n",
      "Train Epoch: 9 [2560/4000 (64%)]\tLoss: 33.379925\n",
      "Train Epoch: 9 [3840/4000 (96%)]\tLoss: 33.265907\n",
      "====> Epoch: 9 Average loss: 33.4594\n",
      "====> Test set loss: 33.3757\n",
      "Train Epoch: 10 [0/4000 (0%)]\tLoss: 33.339733\n",
      "Train Epoch: 10 [1280/4000 (32%)]\tLoss: 33.136345\n",
      "Train Epoch: 10 [2560/4000 (64%)]\tLoss: 33.788853\n",
      "Train Epoch: 10 [3840/4000 (96%)]\tLoss: 33.463074\n",
      "====> Epoch: 10 Average loss: 33.3910\n",
      "====> Test set loss: 33.3170\n",
      "Train Epoch: 11 [0/4000 (0%)]\tLoss: 33.521400\n",
      "Train Epoch: 11 [1280/4000 (32%)]\tLoss: 33.237904\n",
      "Train Epoch: 11 [2560/4000 (64%)]\tLoss: 32.887287\n",
      "Train Epoch: 11 [3840/4000 (96%)]\tLoss: 33.444271\n",
      "====> Epoch: 11 Average loss: 33.3119\n",
      "====> Test set loss: 33.2635\n",
      "Train Epoch: 12 [0/4000 (0%)]\tLoss: 33.026218\n",
      "Train Epoch: 12 [1280/4000 (32%)]\tLoss: 33.090889\n",
      "Train Epoch: 12 [2560/4000 (64%)]\tLoss: 33.572273\n",
      "Train Epoch: 12 [3840/4000 (96%)]\tLoss: 32.982937\n",
      "====> Epoch: 12 Average loss: 33.2426\n",
      "====> Test set loss: 33.2014\n",
      "Train Epoch: 13 [0/4000 (0%)]\tLoss: 33.461472\n",
      "Train Epoch: 13 [1280/4000 (32%)]\tLoss: 32.934235\n",
      "Train Epoch: 13 [2560/4000 (64%)]\tLoss: 33.094650\n",
      "Train Epoch: 13 [3840/4000 (96%)]\tLoss: 33.268742\n",
      "====> Epoch: 13 Average loss: 33.2062\n",
      "====> Test set loss: 33.1797\n",
      "Train Epoch: 14 [0/4000 (0%)]\tLoss: 33.007164\n",
      "Train Epoch: 14 [1280/4000 (32%)]\tLoss: 33.007553\n",
      "Train Epoch: 14 [2560/4000 (64%)]\tLoss: 33.142513\n",
      "Train Epoch: 14 [3840/4000 (96%)]\tLoss: 33.544128\n",
      "====> Epoch: 14 Average loss: 33.1771\n",
      "====> Test set loss: 33.1546\n",
      "Train Epoch: 15 [0/4000 (0%)]\tLoss: 33.386238\n",
      "Train Epoch: 15 [1280/4000 (32%)]\tLoss: 33.292362\n",
      "Train Epoch: 15 [2560/4000 (64%)]\tLoss: 33.311974\n",
      "Train Epoch: 15 [3840/4000 (96%)]\tLoss: 32.850224\n",
      "====> Epoch: 15 Average loss: 33.1378\n",
      "====> Test set loss: 33.1056\n",
      "Train Epoch: 16 [0/4000 (0%)]\tLoss: 32.746498\n",
      "Train Epoch: 16 [1280/4000 (32%)]\tLoss: 32.856152\n",
      "Train Epoch: 16 [2560/4000 (64%)]\tLoss: 33.292179\n",
      "Train Epoch: 16 [3840/4000 (96%)]\tLoss: 33.092487\n",
      "====> Epoch: 16 Average loss: 33.1239\n",
      "====> Test set loss: 33.0570\n",
      "Train Epoch: 17 [0/4000 (0%)]\tLoss: 32.523041\n",
      "Train Epoch: 17 [1280/4000 (32%)]\tLoss: 32.984951\n",
      "Train Epoch: 17 [2560/4000 (64%)]\tLoss: 32.752499\n",
      "Train Epoch: 17 [3840/4000 (96%)]\tLoss: 32.991657\n",
      "====> Epoch: 17 Average loss: 33.0870\n",
      "====> Test set loss: 33.0326\n",
      "Train Epoch: 18 [0/4000 (0%)]\tLoss: 33.595570\n",
      "Train Epoch: 18 [1280/4000 (32%)]\tLoss: 33.054592\n",
      "Train Epoch: 18 [2560/4000 (64%)]\tLoss: 32.936035\n",
      "Train Epoch: 18 [3840/4000 (96%)]\tLoss: 32.889633\n",
      "====> Epoch: 18 Average loss: 33.0801\n",
      "====> Test set loss: 33.0006\n",
      "Train Epoch: 19 [0/4000 (0%)]\tLoss: 33.181126\n",
      "Train Epoch: 19 [1280/4000 (32%)]\tLoss: 32.607975\n",
      "Train Epoch: 19 [2560/4000 (64%)]\tLoss: 33.015804\n",
      "Train Epoch: 19 [3840/4000 (96%)]\tLoss: 32.773071\n",
      "====> Epoch: 19 Average loss: 33.0560\n",
      "====> Test set loss: 33.0339\n",
      "Train Epoch: 20 [0/4000 (0%)]\tLoss: 32.957386\n",
      "Train Epoch: 20 [1280/4000 (32%)]\tLoss: 32.760590\n",
      "Train Epoch: 20 [2560/4000 (64%)]\tLoss: 32.985870\n",
      "Train Epoch: 20 [3840/4000 (96%)]\tLoss: 33.380119\n",
      "====> Epoch: 20 Average loss: 33.0409\n",
      "====> Test set loss: 32.9883\n"
     ]
    }
   ],
   "source": [
    "gradients = torch.zeros(train_data.shape[1]).to(device)\n",
    "for epoch in range(1, n_epochs+1):\n",
    "    grads=train_truncated_with_gradients(train_data, vae_gumbel_truncated, \n",
    "                                         vae_gumbel_trunc_optimizer, epoch, batch_size, Dim = 2*D)\n",
    "    if epoch > 5:\n",
    "        gradients += grads\n",
    "    test(test_data, vae_gumbel_truncated, epoch, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fe76407bd90>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(gradients.clone().detach().cpu().numpy()[:, np.newaxis])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0978, 0.3031, 0.1394, 0.2099, 0.2063, 0.2098, 0.1076, 0.2316, 0.0298,\n",
       "        0.1968, 0.0261, 0.0561, 0.0848, 0.2727, 0.2320, 0.3355, 0.2739, 0.0056,\n",
       "        0.0301, 0.0953, 0.0889, 0.2483, 0.0063, 0.0231, 0.0009, 0.0924, 0.4782,\n",
       "        0.3251, 0.2092, 0.2881], device='cuda:0')"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.mean(dim = 0)[:D]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1104, 0.3139, 0.1557, 0.2146, 0.2272, 0.2249, 0.1142, 0.2374, 0.0551,\n",
       "        0.2214, 0.0421, 0.0623, 0.1154, 0.2879, 0.2327, 0.3289, 0.2827, 0.0258,\n",
       "        0.0542, 0.1214, 0.0979, 0.2593, 0.0293, 0.0478, 0.0303, 0.1002, 0.4750,\n",
       "        0.3373, 0.2328, 0.3169], device='cuda:0', grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae_gumbel_truncated(test_data)[0].mean(dim = 0)[:D]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1913, 0.2338, 0.2076, 0.2199, 0.2306, 0.1890, 0.1805, 0.1945, 0.1051,\n",
       "        0.2321, 0.0976, 0.1389, 0.1652, 0.1922, 0.2341, 0.2330, 0.2048, 0.0390,\n",
       "        0.0929, 0.1692, 0.1755, 0.2236, 0.0499, 0.0923, 0.0152, 0.1863, 0.1593,\n",
       "        0.2244, 0.2096, 0.2350], device='cuda:0')"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.std(dim = 0)[:D]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0501, 0.0326, 0.0511, 0.0527, 0.0521, 0.0503, 0.0500, 0.0543, 0.0409,\n",
       "        0.0507, 0.0335, 0.0402, 0.0560, 0.0382, 0.0569, 0.0347, 0.0369, 0.0242,\n",
       "        0.0387, 0.0613, 0.0464, 0.0418, 0.0283, 0.0363, 0.0296, 0.0466, 0.0253,\n",
       "        0.0410, 0.0482, 0.0477], device='cuda:0', grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae_gumbel_truncated(test_data)[0].std(dim = 0)[:D]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    w = vae_gumbel_truncated.weight_creator(test_data[0:10, :])\n",
    "    subset_indices = sample_subset(w, k=3*z_size, t=global_t).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fe764b2a2d0>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(subset_indices.sum(dim = 0).clone().detach().cpu().numpy()[:, np.newaxis])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4.3291e-03, 1.4547e-15, 8.7694e-07, 7.6677e-11, 1.0488e-12, 4.5284e-22,\n",
       "         3.1184e-21, 5.8956e-14, 6.1925e-08, 1.7970e-09, 6.9047e-11, 4.2175e-04,\n",
       "         2.8686e-05, 8.6152e-13, 8.6113e-13, 2.2741e-09, 2.4467e-24, 2.5500e-11,\n",
       "         5.0110e-27, 6.7680e-07, 2.3052e-06, 2.8021e-04, 7.4786e-08, 6.5251e-13,\n",
       "         3.3192e-13, 1.1250e-06, 1.0398e-25, 3.2190e-01, 2.7976e-08, 1.6642e+00,\n",
       "         7.0213e-12, 1.4591e-03, 6.1645e-01, 3.0926e-02, 9.8761e-01, 3.0614e-15,\n",
       "         1.1301e+00, 1.9841e-05, 1.8680e+00, 1.8548e+00, 1.7920e+00, 1.6336e+00,\n",
       "         6.2688e-03, 2.5296e-06, 2.1825e-09, 7.6417e-01, 2.1222e-17, 2.6941e-18,\n",
       "         3.5835e-04, 1.0205e-07, 1.4725e-03, 3.5150e-13, 2.5258e-08, 1.1281e-10,\n",
       "         1.8517e+00, 9.7199e-20, 4.6978e-01, 2.1964e-07, 6.8764e-16, 3.5069e-16],\n",
       "        [2.8101e-17, 6.1266e-08, 1.5983e-13, 2.0539e-05, 3.0490e-14, 2.7371e-19,\n",
       "         1.0197e-10, 2.5183e-12, 1.7383e-12, 7.7211e-08, 1.1724e-17, 1.6453e-08,\n",
       "         3.5100e-18, 1.0168e-08, 1.1674e-06, 8.3762e-09, 3.4909e-07, 3.2323e-05,\n",
       "         5.8798e-15, 3.8638e-12, 1.4370e-10, 4.0909e-08, 2.7704e-42, 1.3881e-28,\n",
       "         1.2237e-06, 7.4390e-14, 1.0057e-07, 1.5553e-04, 4.7709e-16, 1.4656e+00,\n",
       "         2.6764e-06, 3.6116e-02, 8.5028e-13, 1.4762e+00, 2.7926e-04, 3.5603e-13,\n",
       "         9.8818e-17, 1.2089e-01, 1.6427e+00, 9.4255e-01, 9.4026e-01, 1.8161e+00,\n",
       "         1.5803e-02, 1.1261e-03, 1.6841e-14, 1.6369e+00, 6.2575e-03, 3.8813e-09,\n",
       "         1.1557e+00, 2.5144e-07, 5.2393e-07, 1.8562e+00, 1.2001e-10, 6.5093e-08,\n",
       "         1.2248e+00, 5.2383e-12, 2.7557e-04, 6.6198e-01, 9.4212e-05, 4.3491e-27],\n",
       "        [1.6306e-07, 2.0805e-14, 1.6375e-04, 7.6444e-09, 4.9977e-21, 5.7411e-09,\n",
       "         9.2374e-10, 2.9110e-09, 1.0202e-09, 1.4436e-14, 1.6474e-09, 1.9085e-09,\n",
       "         1.6225e-10, 8.8326e-12, 6.6796e-05, 5.3661e-17, 8.5474e-26, 6.0723e-07,\n",
       "         4.1811e-21, 1.3770e-02, 1.0137e-06, 1.0144e-11, 1.3132e-02, 1.4114e-10,\n",
       "         9.4500e-18, 3.6763e-13, 1.6914e-11, 1.7107e-04, 3.1675e-09, 1.1698e+00,\n",
       "         6.7472e-08, 1.0610e-10, 1.6012e+00, 4.5235e-01, 6.4817e-01, 1.0400e-09,\n",
       "         1.2761e+00, 4.7384e-02, 1.1117e+00, 3.6368e-05, 1.0000e+00, 1.0458e-03,\n",
       "         1.2780e+00, 1.4850e+00, 4.4738e-08, 4.5621e-01, 2.7731e-11, 1.1380e-09,\n",
       "         1.6992e-01, 1.6338e-07, 9.4578e-15, 1.5617e+00, 8.8846e-16, 1.8459e-04,\n",
       "         1.1987e+00, 2.1891e-12, 7.9749e-01, 7.1774e-01, 1.8871e-06, 1.7405e-09],\n",
       "        [2.6090e-06, 1.0626e-05, 1.1387e-23, 1.3377e-05, 1.7747e-11, 1.8491e-06,\n",
       "         7.3133e-07, 1.1786e-07, 3.3216e-12, 1.2041e-11, 9.9472e-14, 1.2139e-11,\n",
       "         4.4146e-10, 1.1029e-04, 3.9258e-13, 1.0010e-12, 6.1137e-06, 3.3606e-07,\n",
       "         3.0921e-06, 5.5798e-07, 2.0578e-11, 7.3570e-09, 2.0420e-05, 6.4431e-05,\n",
       "         4.3077e-13, 7.8608e-20, 2.5497e-13, 7.0689e-01, 6.7100e-13, 1.8160e+00,\n",
       "         1.4019e-15, 2.4672e-01, 1.2106e+00, 3.8001e-01, 9.9996e-01, 6.6026e-13,\n",
       "         9.7391e-01, 1.6658e-02, 1.2291e+00, 1.3354e+00, 5.6959e-05, 2.4830e-02,\n",
       "         3.2298e-05, 4.2292e-01, 9.0678e-10, 2.7240e-07, 1.0575e-11, 1.3171e-16,\n",
       "         1.3219e+00, 2.5248e-11, 7.0581e-04, 1.7659e+00, 4.5362e-06, 6.3334e-12,\n",
       "         1.0433e+00, 2.7603e-07, 4.4878e-01, 1.0562e+00, 1.1462e-08, 1.8518e-06],\n",
       "        [1.8821e-10, 3.8070e-15, 5.5610e-12, 1.8804e-17, 5.9744e-14, 9.1060e-10,\n",
       "         1.5474e-13, 2.7409e-09, 1.3818e-06, 1.3577e-09, 3.7938e-16, 1.5752e-01,\n",
       "         1.6144e-07, 7.4955e-07, 9.5624e-08, 8.8345e-10, 9.4087e-04, 4.5376e-10,\n",
       "         2.0336e-04, 2.6611e-11, 1.5492e-03, 3.9903e-11, 6.7001e-04, 6.4691e-06,\n",
       "         1.7255e-09, 1.5394e-12, 5.9227e-05, 4.5592e-11, 3.1340e-03, 1.5528e+00,\n",
       "         4.0093e-03, 1.3790e-04, 4.6557e-03, 9.6333e-01, 9.8526e-01, 1.5606e-22,\n",
       "         7.5211e-09, 1.0708e-05, 1.4244e+00, 1.3394e+00, 1.3029e-13, 1.2916e-07,\n",
       "         1.0718e+00, 7.5260e-05, 7.7582e-10, 9.7454e-01, 1.4698e-10, 1.0793e-10,\n",
       "         1.0276e-09, 1.9267e-09, 4.2155e-11, 2.1159e+00, 3.3563e-05, 2.1527e-04,\n",
       "         1.6144e+00, 2.0311e-08, 2.1433e+00, 6.4167e-01, 1.1456e-26, 2.6093e-16],\n",
       "        [6.3507e-09, 6.3974e-18, 2.6109e-17, 3.5873e-06, 1.1995e-01, 2.1749e-13,\n",
       "         1.1587e-02, 2.4072e-06, 1.4291e-16, 7.4340e-08, 5.4851e-07, 5.4794e-05,\n",
       "         7.3356e-13, 6.0835e-04, 2.7961e-02, 1.7087e-04, 5.3594e-14, 3.0722e-03,\n",
       "         2.8349e-18, 4.1089e-08, 9.8992e-08, 1.0755e-13, 1.9683e-07, 6.3845e-03,\n",
       "         1.4719e-06, 4.4583e-07, 1.2289e-22, 1.7807e-02, 1.2731e-12, 2.7321e-07,\n",
       "         4.0089e-10, 6.1512e-02, 1.4667e+00, 3.6302e-01, 2.6884e+00, 1.6955e-05,\n",
       "         1.9378e+00, 3.0993e-01, 1.5196e-03, 1.6363e+00, 1.3583e+00, 1.2468e-20,\n",
       "         3.0735e-10, 3.4761e-22, 3.0426e-11, 1.3858e+00, 1.9575e-14, 9.9488e-23,\n",
       "         2.7973e-01, 5.0922e-09, 2.5691e-02, 2.0216e+00, 5.3880e-12, 7.4116e-11,\n",
       "         5.3632e-09, 4.1988e-07, 5.8626e-07, 1.2760e+00, 1.1165e-06, 9.5632e-09],\n",
       "        [2.9804e-14, 3.2462e-05, 3.0471e-06, 3.9818e-11, 2.3465e-01, 4.5850e-11,\n",
       "         5.7394e-12, 3.6301e-06, 2.7607e-07, 3.5385e-03, 2.8796e-21, 1.6109e-09,\n",
       "         5.7538e-01, 2.9194e-09, 8.2528e-03, 2.7310e-07, 1.8653e-05, 2.1551e-17,\n",
       "         3.7242e-10, 7.3657e-07, 3.0298e-04, 1.5704e-08, 6.2875e-19, 7.2781e-18,\n",
       "         1.5916e-15, 1.1739e-12, 2.1927e-15, 1.6227e-17, 1.0874e-03, 8.0903e-01,\n",
       "         2.5106e-09, 9.9426e-18, 1.1624e+00, 1.5040e+00, 8.3180e-01, 1.7169e-13,\n",
       "         1.7074e-06, 6.1566e-01, 9.9945e-10, 1.0816e+00, 6.8945e-01, 1.2974e+00,\n",
       "         1.6411e+00, 1.0713e-02, 1.5803e-04, 2.6290e-08, 1.9632e-08, 7.0524e-03,\n",
       "         1.6438e+00, 6.6967e-29, 2.7030e-07, 1.6469e+00, 9.8957e-15, 7.8258e-07,\n",
       "         1.9756e-03, 9.8423e-08, 9.9991e-01, 2.0885e-01, 4.1664e-08, 2.4901e-02],\n",
       "        [6.3371e-04, 1.1354e-14, 1.8753e-19, 6.6360e-06, 1.1425e-03, 4.3613e-06,\n",
       "         7.6224e-06, 2.8734e-05, 4.4257e-07, 2.4187e-02, 2.1563e-01, 1.8847e-04,\n",
       "         1.2216e-03, 1.0479e-10, 2.1135e-04, 5.0650e-11, 6.9494e-14, 3.4413e-11,\n",
       "         2.5781e-07, 2.8609e-14, 2.7511e-01, 5.0426e-07, 2.0492e-02, 3.1102e-07,\n",
       "         1.3820e-10, 1.1652e-04, 3.5773e-06, 2.5960e-06, 1.3530e-07, 1.3388e+00,\n",
       "         3.0794e-30, 3.7001e-01, 1.3258e+00, 4.1167e-01, 9.5564e-01, 3.5614e-07,\n",
       "         1.1914e+00, 9.6297e-01, 1.1222e+00, 1.2465e+00, 1.0837e+00, 7.9062e-01,\n",
       "         1.2992e+00, 6.6843e-05, 3.7250e-06, 3.4441e-01, 9.9125e-07, 1.3046e-24,\n",
       "         4.5442e-03, 7.2972e-13, 2.9796e-08, 7.9354e-01, 3.3002e-07, 8.1119e-14,\n",
       "         3.1580e-03, 4.1755e-15, 7.5857e-01, 4.5819e-01, 4.0670e-17, 3.3919e-12],\n",
       "        [1.8121e-04, 6.1351e-07, 7.0210e-08, 1.6885e-06, 4.5929e-15, 8.7776e-15,\n",
       "         2.0627e-12, 1.6229e-05, 1.4571e-17, 8.9898e-03, 5.0242e-02, 4.0503e-17,\n",
       "         2.0194e-10, 2.0301e-07, 1.9194e-19, 9.3783e-21, 4.6281e-06, 1.7192e-17,\n",
       "         1.6949e-02, 1.7937e-11, 2.3902e-03, 7.3231e-05, 8.3105e-11, 8.8810e-04,\n",
       "         3.3968e-05, 7.6953e-07, 1.5699e-07, 1.0059e-15, 5.3727e-07, 1.9861e+00,\n",
       "         2.5731e-08, 2.9286e-01, 2.7711e-02, 1.2105e+00, 1.5963e+00, 5.9519e-14,\n",
       "         1.0084e-14, 1.3540e-07, 9.2108e-01, 2.0050e-11, 1.9881e+00, 6.5777e-01,\n",
       "         3.9462e-24, 7.0983e-01, 5.4091e-23, 1.7833e+00, 2.5120e-19, 2.3775e-07,\n",
       "         1.0039e+00, 7.4454e-15, 1.7890e-04, 6.3224e-01, 6.4256e-06, 5.7528e-11,\n",
       "         5.8901e-03, 3.3963e-10, 8.1952e-01, 1.2850e+00, 7.4336e-09, 3.5534e-07],\n",
       "        [1.8895e-03, 2.3488e-17, 3.6723e-06, 3.8713e-03, 2.1622e-07, 1.0386e-12,\n",
       "         2.6133e-11, 3.7419e-07, 1.3821e-06, 2.4074e-05, 1.3059e-07, 1.0488e-10,\n",
       "         1.2639e-02, 7.5108e-12, 2.7526e-06, 6.2140e-02, 6.9522e-17, 1.3929e-03,\n",
       "         6.6384e-18, 1.5192e-06, 5.5080e-09, 1.2270e-08, 2.3160e-08, 1.3733e-11,\n",
       "         5.2496e-10, 9.0268e-14, 8.1963e-04, 5.9304e-09, 2.0903e-13, 9.9221e-01,\n",
       "         6.0805e-02, 5.8139e-01, 1.2994e+00, 3.3195e-02, 1.0078e+00, 7.5614e-07,\n",
       "         1.3636e+00, 1.3174e+00, 9.8075e-01, 4.9733e-05, 1.8589e-04, 1.2277e+00,\n",
       "         1.2011e+00, 4.4511e-12, 9.0152e-22, 1.4093e+00, 2.1475e-01, 3.3592e-10,\n",
       "         1.0148e+00, 3.0105e-09, 7.2987e-13, 2.2071e-16, 6.0723e-13, 9.3355e-09,\n",
       "         1.0262e+00, 4.0260e-09, 6.4431e-02, 1.1223e+00, 4.9888e-25, 1.5596e-07]])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[38, 39, 54, 40, 29, 41, 36, 34, 45, 32, 56, 27, 33, 42,  0],\n",
       "        [51, 41, 38, 45, 33, 29, 54, 48, 39, 40, 57, 37, 31, 42, 46],\n",
       "        [32, 51, 43, 42, 36, 54, 29, 38, 40, 56, 57, 34, 45, 33, 48],\n",
       "        [29, 51, 39, 48, 38, 32, 57, 54, 34, 36, 27, 56, 43, 33, 31],\n",
       "        [56, 51, 54, 29, 38, 39, 42, 34, 45, 33, 57, 11, 32, 30, 28],\n",
       "        [34, 51, 36, 39, 32, 45, 40, 57, 33, 37, 48,  4, 31, 14, 50],\n",
       "        [51, 48, 42, 33, 41, 32, 39, 56, 34, 29, 40, 37, 12,  4, 57],\n",
       "        [29, 32, 42, 39, 36, 38, 40, 37, 34, 51, 41, 56, 57, 33, 31],\n",
       "        [40, 29, 45, 34, 57, 33, 48, 38, 56, 43, 41, 51, 31, 10, 32],\n",
       "        [45, 36, 37, 32, 41, 42, 57, 54, 48, 34, 29, 38, 31, 46, 56]])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argsort(subset_indices, dim = 1, descending = True)[:, :3*z_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(15.7327)\n",
      "tensor(134.2672)\n"
     ]
    }
   ],
   "source": [
    "print(subset_indices[:, :D].sum())\n",
    "\n",
    "print(subset_indices[:, D:2*D].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(10, device='cuda:0')"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(w.argsort(descending= True)[:, :3*z_size] < 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How does a normal VAE do?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying to reconstruct first 30 features only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "vanilla_vae = VAE(2*D, 100, 20)\n",
    "\n",
    "vanilla_vae.to(device)\n",
    "vanilla_vae_optimizer = torch.optim.Adam(vanilla_vae.parameters(), \n",
    "                                            lr=lr,\n",
    "                                            betas = (b1,b2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/4000 (0%)]\tLoss: 20.811413\n",
      "Train Epoch: 1 [1280/4000 (32%)]\tLoss: 20.117807\n",
      "Train Epoch: 1 [2560/4000 (64%)]\tLoss: 19.581526\n",
      "Train Epoch: 1 [3840/4000 (96%)]\tLoss: 19.099516\n",
      "====> Epoch: 1 Average loss: 19.9070\n",
      "====> Test set loss: 40.0846\n",
      "Train Epoch: 2 [0/4000 (0%)]\tLoss: 19.055134\n",
      "Train Epoch: 2 [1280/4000 (32%)]\tLoss: 18.440933\n",
      "Train Epoch: 2 [2560/4000 (64%)]\tLoss: 17.732121\n",
      "Train Epoch: 2 [3840/4000 (96%)]\tLoss: 17.247393\n",
      "====> Epoch: 2 Average loss: 18.0550\n",
      "====> Test set loss: 38.0334\n",
      "Train Epoch: 3 [0/4000 (0%)]\tLoss: 16.820208\n",
      "Train Epoch: 3 [1280/4000 (32%)]\tLoss: 15.795731\n",
      "Train Epoch: 3 [2560/4000 (64%)]\tLoss: 15.425953\n",
      "Train Epoch: 3 [3840/4000 (96%)]\tLoss: 15.025915\n",
      "====> Epoch: 3 Average loss: 15.5690\n",
      "====> Test set loss: 36.1794\n",
      "Train Epoch: 4 [0/4000 (0%)]\tLoss: 14.359447\n",
      "Train Epoch: 4 [1280/4000 (32%)]\tLoss: 13.912736\n",
      "Train Epoch: 4 [2560/4000 (64%)]\tLoss: 14.012361\n",
      "Train Epoch: 4 [3840/4000 (96%)]\tLoss: 13.733294\n",
      "====> Epoch: 4 Average loss: 13.8593\n",
      "====> Test set loss: 35.4909\n",
      "Train Epoch: 5 [0/4000 (0%)]\tLoss: 13.429065\n",
      "Train Epoch: 5 [1280/4000 (32%)]\tLoss: 13.251121\n",
      "Train Epoch: 5 [2560/4000 (64%)]\tLoss: 12.818075\n",
      "Train Epoch: 5 [3840/4000 (96%)]\tLoss: 13.156096\n",
      "====> Epoch: 5 Average loss: 13.2502\n",
      "====> Test set loss: 35.1064\n",
      "Train Epoch: 6 [0/4000 (0%)]\tLoss: 13.052223\n",
      "Train Epoch: 6 [1280/4000 (32%)]\tLoss: 13.080382\n",
      "Train Epoch: 6 [2560/4000 (64%)]\tLoss: 12.995548\n",
      "Train Epoch: 6 [3840/4000 (96%)]\tLoss: 12.967505\n",
      "====> Epoch: 6 Average loss: 12.9611\n",
      "====> Test set loss: 34.8209\n",
      "Train Epoch: 7 [0/4000 (0%)]\tLoss: 12.658567\n",
      "Train Epoch: 7 [1280/4000 (32%)]\tLoss: 12.638159\n",
      "Train Epoch: 7 [2560/4000 (64%)]\tLoss: 12.754868\n",
      "Train Epoch: 7 [3840/4000 (96%)]\tLoss: 13.064964\n",
      "====> Epoch: 7 Average loss: 12.7406\n",
      "====> Test set loss: 34.6553\n",
      "Train Epoch: 8 [0/4000 (0%)]\tLoss: 12.741595\n",
      "Train Epoch: 8 [1280/4000 (32%)]\tLoss: 12.784866\n",
      "Train Epoch: 8 [2560/4000 (64%)]\tLoss: 12.253778\n",
      "Train Epoch: 8 [3840/4000 (96%)]\tLoss: 12.060513\n",
      "====> Epoch: 8 Average loss: 12.5933\n",
      "====> Test set loss: 34.4474\n",
      "Train Epoch: 9 [0/4000 (0%)]\tLoss: 12.047246\n",
      "Train Epoch: 9 [1280/4000 (32%)]\tLoss: 12.320334\n",
      "Train Epoch: 9 [2560/4000 (64%)]\tLoss: 12.659516\n",
      "Train Epoch: 9 [3840/4000 (96%)]\tLoss: 12.286519\n",
      "====> Epoch: 9 Average loss: 12.4926\n",
      "====> Test set loss: 34.3596\n",
      "Train Epoch: 10 [0/4000 (0%)]\tLoss: 12.459833\n",
      "Train Epoch: 10 [1280/4000 (32%)]\tLoss: 12.387986\n",
      "Train Epoch: 10 [2560/4000 (64%)]\tLoss: 12.445711\n",
      "Train Epoch: 10 [3840/4000 (96%)]\tLoss: 12.209690\n",
      "====> Epoch: 10 Average loss: 12.3740\n",
      "====> Test set loss: 34.2252\n",
      "Train Epoch: 11 [0/4000 (0%)]\tLoss: 12.193333\n",
      "Train Epoch: 11 [1280/4000 (32%)]\tLoss: 11.944195\n",
      "Train Epoch: 11 [2560/4000 (64%)]\tLoss: 12.180675\n",
      "Train Epoch: 11 [3840/4000 (96%)]\tLoss: 12.330107\n",
      "====> Epoch: 11 Average loss: 12.2346\n",
      "====> Test set loss: 34.0704\n",
      "Train Epoch: 12 [0/4000 (0%)]\tLoss: 11.939956\n",
      "Train Epoch: 12 [1280/4000 (32%)]\tLoss: 11.912784\n",
      "Train Epoch: 12 [2560/4000 (64%)]\tLoss: 12.369015\n",
      "Train Epoch: 12 [3840/4000 (96%)]\tLoss: 11.832901\n",
      "====> Epoch: 12 Average loss: 12.1093\n",
      "====> Test set loss: 33.9149\n",
      "Train Epoch: 13 [0/4000 (0%)]\tLoss: 11.867705\n",
      "Train Epoch: 13 [1280/4000 (32%)]\tLoss: 11.936132\n",
      "Train Epoch: 13 [2560/4000 (64%)]\tLoss: 11.864071\n",
      "Train Epoch: 13 [3840/4000 (96%)]\tLoss: 11.690831\n",
      "====> Epoch: 13 Average loss: 11.9878\n",
      "====> Test set loss: 33.8119\n",
      "Train Epoch: 14 [0/4000 (0%)]\tLoss: 12.333431\n",
      "Train Epoch: 14 [1280/4000 (32%)]\tLoss: 11.722173\n",
      "Train Epoch: 14 [2560/4000 (64%)]\tLoss: 11.642587\n",
      "Train Epoch: 14 [3840/4000 (96%)]\tLoss: 12.001178\n",
      "====> Epoch: 14 Average loss: 11.7956\n",
      "====> Test set loss: 33.5847\n",
      "Train Epoch: 15 [0/4000 (0%)]\tLoss: 11.726013\n",
      "Train Epoch: 15 [1280/4000 (32%)]\tLoss: 11.483834\n",
      "Train Epoch: 15 [2560/4000 (64%)]\tLoss: 11.958052\n",
      "Train Epoch: 15 [3840/4000 (96%)]\tLoss: 11.759382\n",
      "====> Epoch: 15 Average loss: 11.6284\n",
      "====> Test set loss: 33.5229\n",
      "Train Epoch: 16 [0/4000 (0%)]\tLoss: 11.732525\n",
      "Train Epoch: 16 [1280/4000 (32%)]\tLoss: 11.418179\n",
      "Train Epoch: 16 [2560/4000 (64%)]\tLoss: 11.261450\n",
      "Train Epoch: 16 [3840/4000 (96%)]\tLoss: 11.341302\n",
      "====> Epoch: 16 Average loss: 11.5207\n",
      "====> Test set loss: 33.4302\n",
      "Train Epoch: 17 [0/4000 (0%)]\tLoss: 11.256811\n",
      "Train Epoch: 17 [1280/4000 (32%)]\tLoss: 11.560511\n",
      "Train Epoch: 17 [2560/4000 (64%)]\tLoss: 11.444053\n",
      "Train Epoch: 17 [3840/4000 (96%)]\tLoss: 11.189885\n",
      "====> Epoch: 17 Average loss: 11.4202\n",
      "====> Test set loss: 33.3466\n",
      "Train Epoch: 18 [0/4000 (0%)]\tLoss: 11.305147\n",
      "Train Epoch: 18 [1280/4000 (32%)]\tLoss: 11.120952\n",
      "Train Epoch: 18 [2560/4000 (64%)]\tLoss: 11.764889\n",
      "Train Epoch: 18 [3840/4000 (96%)]\tLoss: 11.196559\n",
      "====> Epoch: 18 Average loss: 11.3688\n",
      "====> Test set loss: 33.2598\n",
      "Train Epoch: 19 [0/4000 (0%)]\tLoss: 11.134405\n",
      "Train Epoch: 19 [1280/4000 (32%)]\tLoss: 11.195744\n",
      "Train Epoch: 19 [2560/4000 (64%)]\tLoss: 11.448055\n",
      "Train Epoch: 19 [3840/4000 (96%)]\tLoss: 11.099967\n",
      "====> Epoch: 19 Average loss: 11.3036\n",
      "====> Test set loss: 33.2559\n",
      "Train Epoch: 20 [0/4000 (0%)]\tLoss: 11.517477\n",
      "Train Epoch: 20 [1280/4000 (32%)]\tLoss: 11.305155\n",
      "Train Epoch: 20 [2560/4000 (64%)]\tLoss: 11.059983\n",
      "Train Epoch: 20 [3840/4000 (96%)]\tLoss: 11.152271\n",
      "====> Epoch: 20 Average loss: 11.2555\n",
      "====> Test set loss: 33.1565\n"
     ]
    }
   ],
   "source": [
    "gradients = torch.zeros(train_data.shape[1]).to(device)\n",
    "for epoch in range(1, n_epochs+1):\n",
    "    grads=train_truncated_with_gradients(train_data, vanilla_vae, \n",
    "                                         vanilla_vae_optimizer, epoch, batch_size, Dim = D)\n",
    "    if epoch > 5:\n",
    "        gradients += grads\n",
    "    test(test_data, vanilla_vae, epoch, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fe74c9c60d0>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(gradients.clone().detach().cpu().numpy()[:, np.newaxis])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0978, 0.3031, 0.1394, 0.2099, 0.2063, 0.2098, 0.1076, 0.2316, 0.0298,\n",
       "        0.1968, 0.0261, 0.0561, 0.0848, 0.2727, 0.2320, 0.3355, 0.2739, 0.0056,\n",
       "        0.0301, 0.0953, 0.0889, 0.2483, 0.0063, 0.0231, 0.0009, 0.0924, 0.4782,\n",
       "        0.3251, 0.2092, 0.2881], device='cuda:0')"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.mean(dim = 0)[:D]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1036, 0.3097, 0.1537, 0.2227, 0.2226, 0.2176, 0.1148, 0.2424, 0.0421,\n",
       "        0.2119, 0.0362, 0.0667, 0.1112, 0.2861, 0.2370, 0.3406, 0.2877, 0.0284,\n",
       "        0.0396, 0.1004, 0.1061, 0.2595, 0.0237, 0.0369, 0.0217, 0.1056, 0.4770,\n",
       "        0.3284, 0.2258, 0.3023], device='cuda:0', grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vanilla_vae(test_data)[0].mean(dim = 0)[:D]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1913, 0.2338, 0.2076, 0.2199, 0.2306, 0.1890, 0.1805, 0.1945, 0.1051,\n",
       "        0.2321, 0.0976, 0.1389, 0.1652, 0.1922, 0.2341, 0.2330, 0.2048, 0.0390,\n",
       "        0.0929, 0.1692, 0.1755, 0.2236, 0.0499, 0.0923, 0.0152, 0.1863, 0.1593,\n",
       "        0.2244, 0.2096, 0.2350], device='cuda:0')"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.std(dim = 0)[:D]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0777, 0.0582, 0.1372, 0.1327, 0.0643, 0.0709, 0.1264, 0.1545, 0.0461,\n",
       "        0.1284, 0.0444, 0.0733, 0.0907, 0.1657, 0.2094, 0.1932, 0.0638, 0.0405,\n",
       "        0.0433, 0.0668, 0.1062, 0.1279, 0.0356, 0.0440, 0.0329, 0.1379, 0.0646,\n",
       "        0.1776, 0.0763, 0.1769], device='cuda:0', grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vanilla_vae(test_data)[0].std(dim = 0)[:D]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at all dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "vanilla_vae = VAE(2*D, 100, 20)\n",
    "\n",
    "vanilla_vae.to(device)\n",
    "vanilla_vae_optimizer = torch.optim.Adam(vanilla_vae.parameters(), \n",
    "                                            lr=lr,\n",
    "                                            betas = (b1,b2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/4000 (0%)]\tLoss: 42.770042\n",
      "Train Epoch: 1 [1280/4000 (32%)]\tLoss: 42.121311\n",
      "Train Epoch: 1 [2560/4000 (64%)]\tLoss: 41.527489\n",
      "Train Epoch: 1 [3840/4000 (96%)]\tLoss: 41.010853\n",
      "====> Epoch: 1 Average loss: 41.7969\n",
      "====> Test set loss: 40.9561\n",
      "Train Epoch: 2 [0/4000 (0%)]\tLoss: 41.069691\n",
      "Train Epoch: 2 [1280/4000 (32%)]\tLoss: 40.465618\n",
      "Train Epoch: 2 [2560/4000 (64%)]\tLoss: 39.950092\n",
      "Train Epoch: 2 [3840/4000 (96%)]\tLoss: 39.169994\n",
      "====> Epoch: 2 Average loss: 40.1527\n",
      "====> Test set loss: 39.1702\n",
      "Train Epoch: 3 [0/4000 (0%)]\tLoss: 39.259609\n",
      "Train Epoch: 3 [1280/4000 (32%)]\tLoss: 38.488525\n",
      "Train Epoch: 3 [2560/4000 (64%)]\tLoss: 37.705387\n",
      "Train Epoch: 3 [3840/4000 (96%)]\tLoss: 36.736557\n",
      "====> Epoch: 3 Average loss: 37.9552\n",
      "====> Test set loss: 36.4830\n",
      "Train Epoch: 4 [0/4000 (0%)]\tLoss: 36.714951\n",
      "Train Epoch: 4 [1280/4000 (32%)]\tLoss: 35.803600\n",
      "Train Epoch: 4 [2560/4000 (64%)]\tLoss: 35.414822\n",
      "Train Epoch: 4 [3840/4000 (96%)]\tLoss: 35.074821\n",
      "====> Epoch: 4 Average loss: 35.6465\n",
      "====> Test set loss: 35.0146\n",
      "Train Epoch: 5 [0/4000 (0%)]\tLoss: 34.760128\n",
      "Train Epoch: 5 [1280/4000 (32%)]\tLoss: 34.835148\n",
      "Train Epoch: 5 [2560/4000 (64%)]\tLoss: 34.409588\n",
      "Train Epoch: 5 [3840/4000 (96%)]\tLoss: 34.124977\n",
      "====> Epoch: 5 Average loss: 34.6386\n",
      "====> Test set loss: 34.3091\n",
      "Train Epoch: 6 [0/4000 (0%)]\tLoss: 33.895832\n",
      "Train Epoch: 6 [1280/4000 (32%)]\tLoss: 34.191303\n",
      "Train Epoch: 6 [2560/4000 (64%)]\tLoss: 34.028492\n",
      "Train Epoch: 6 [3840/4000 (96%)]\tLoss: 33.953178\n",
      "====> Epoch: 6 Average loss: 34.1608\n",
      "====> Test set loss: 33.9358\n",
      "Train Epoch: 7 [0/4000 (0%)]\tLoss: 34.063324\n",
      "Train Epoch: 7 [1280/4000 (32%)]\tLoss: 34.022747\n",
      "Train Epoch: 7 [2560/4000 (64%)]\tLoss: 33.445869\n",
      "Train Epoch: 7 [3840/4000 (96%)]\tLoss: 33.669788\n",
      "====> Epoch: 7 Average loss: 33.8332\n",
      "====> Test set loss: 33.7133\n",
      "Train Epoch: 8 [0/4000 (0%)]\tLoss: 33.936642\n",
      "Train Epoch: 8 [1280/4000 (32%)]\tLoss: 33.466248\n",
      "Train Epoch: 8 [2560/4000 (64%)]\tLoss: 33.680504\n",
      "Train Epoch: 8 [3840/4000 (96%)]\tLoss: 33.869831\n",
      "====> Epoch: 8 Average loss: 33.6381\n",
      "====> Test set loss: 33.5575\n",
      "Train Epoch: 9 [0/4000 (0%)]\tLoss: 33.603279\n",
      "Train Epoch: 9 [1280/4000 (32%)]\tLoss: 33.632488\n",
      "Train Epoch: 9 [2560/4000 (64%)]\tLoss: 33.034866\n",
      "Train Epoch: 9 [3840/4000 (96%)]\tLoss: 33.482704\n",
      "====> Epoch: 9 Average loss: 33.5015\n",
      "====> Test set loss: 33.3954\n",
      "Train Epoch: 10 [0/4000 (0%)]\tLoss: 33.094482\n",
      "Train Epoch: 10 [1280/4000 (32%)]\tLoss: 33.368462\n",
      "Train Epoch: 10 [2560/4000 (64%)]\tLoss: 33.228592\n",
      "Train Epoch: 10 [3840/4000 (96%)]\tLoss: 33.632771\n",
      "====> Epoch: 10 Average loss: 33.3426\n",
      "====> Test set loss: 33.2763\n",
      "Train Epoch: 11 [0/4000 (0%)]\tLoss: 33.270432\n",
      "Train Epoch: 11 [1280/4000 (32%)]\tLoss: 33.190216\n",
      "Train Epoch: 11 [2560/4000 (64%)]\tLoss: 33.301041\n",
      "Train Epoch: 11 [3840/4000 (96%)]\tLoss: 33.453842\n",
      "====> Epoch: 11 Average loss: 33.2424\n",
      "====> Test set loss: 33.1735\n",
      "Train Epoch: 12 [0/4000 (0%)]\tLoss: 32.941502\n",
      "Train Epoch: 12 [1280/4000 (32%)]\tLoss: 33.647461\n",
      "Train Epoch: 12 [2560/4000 (64%)]\tLoss: 32.992001\n",
      "Train Epoch: 12 [3840/4000 (96%)]\tLoss: 33.124840\n",
      "====> Epoch: 12 Average loss: 33.1682\n",
      "====> Test set loss: 33.0889\n",
      "Train Epoch: 13 [0/4000 (0%)]\tLoss: 33.250591\n",
      "Train Epoch: 13 [1280/4000 (32%)]\tLoss: 32.828533\n",
      "Train Epoch: 13 [2560/4000 (64%)]\tLoss: 33.108677\n",
      "Train Epoch: 13 [3840/4000 (96%)]\tLoss: 32.955158\n",
      "====> Epoch: 13 Average loss: 33.0617\n",
      "====> Test set loss: 32.9888\n",
      "Train Epoch: 14 [0/4000 (0%)]\tLoss: 33.234329\n",
      "Train Epoch: 14 [1280/4000 (32%)]\tLoss: 32.789047\n",
      "Train Epoch: 14 [2560/4000 (64%)]\tLoss: 32.755112\n",
      "Train Epoch: 14 [3840/4000 (96%)]\tLoss: 32.940891\n",
      "====> Epoch: 14 Average loss: 32.9585\n",
      "====> Test set loss: 32.8624\n",
      "Train Epoch: 15 [0/4000 (0%)]\tLoss: 33.330830\n",
      "Train Epoch: 15 [1280/4000 (32%)]\tLoss: 32.301254\n",
      "Train Epoch: 15 [2560/4000 (64%)]\tLoss: 32.986771\n",
      "Train Epoch: 15 [3840/4000 (96%)]\tLoss: 32.720535\n",
      "====> Epoch: 15 Average loss: 32.8315\n",
      "====> Test set loss: 32.7489\n",
      "Train Epoch: 16 [0/4000 (0%)]\tLoss: 32.357544\n",
      "Train Epoch: 16 [1280/4000 (32%)]\tLoss: 32.966717\n",
      "Train Epoch: 16 [2560/4000 (64%)]\tLoss: 32.272823\n",
      "Train Epoch: 16 [3840/4000 (96%)]\tLoss: 32.735611\n",
      "====> Epoch: 16 Average loss: 32.7051\n",
      "====> Test set loss: 32.6025\n",
      "Train Epoch: 17 [0/4000 (0%)]\tLoss: 32.390854\n",
      "Train Epoch: 17 [1280/4000 (32%)]\tLoss: 32.396851\n",
      "Train Epoch: 17 [2560/4000 (64%)]\tLoss: 32.267517\n",
      "Train Epoch: 17 [3840/4000 (96%)]\tLoss: 32.485233\n",
      "====> Epoch: 17 Average loss: 32.5417\n",
      "====> Test set loss: 32.4474\n",
      "Train Epoch: 18 [0/4000 (0%)]\tLoss: 32.378201\n",
      "Train Epoch: 18 [1280/4000 (32%)]\tLoss: 32.825802\n",
      "Train Epoch: 18 [2560/4000 (64%)]\tLoss: 32.225758\n",
      "Train Epoch: 18 [3840/4000 (96%)]\tLoss: 32.292000\n",
      "====> Epoch: 18 Average loss: 32.3699\n",
      "====> Test set loss: 32.2608\n",
      "Train Epoch: 19 [0/4000 (0%)]\tLoss: 32.485447\n",
      "Train Epoch: 19 [1280/4000 (32%)]\tLoss: 32.337795\n",
      "Train Epoch: 19 [2560/4000 (64%)]\tLoss: 32.077522\n",
      "Train Epoch: 19 [3840/4000 (96%)]\tLoss: 32.424332\n",
      "====> Epoch: 19 Average loss: 32.2139\n",
      "====> Test set loss: 32.1162\n",
      "Train Epoch: 20 [0/4000 (0%)]\tLoss: 31.833296\n",
      "Train Epoch: 20 [1280/4000 (32%)]\tLoss: 32.057045\n",
      "Train Epoch: 20 [2560/4000 (64%)]\tLoss: 32.209801\n",
      "Train Epoch: 20 [3840/4000 (96%)]\tLoss: 32.094845\n",
      "====> Epoch: 20 Average loss: 32.0879\n",
      "====> Test set loss: 32.0024\n"
     ]
    }
   ],
   "source": [
    "gradients = torch.zeros(train_data.shape[1]).to(device)\n",
    "for epoch in range(1, n_epochs+1):\n",
    "    grads=train_truncated_with_gradients(train_data, vanilla_vae, \n",
    "                                         vanilla_vae_optimizer, epoch, batch_size, Dim = 2*D)\n",
    "    if epoch > 5:\n",
    "        gradients += grads\n",
    "    test(test_data, vanilla_vae, epoch, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fe74c9df690>"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(gradients.clone().detach().cpu().numpy()[:, np.newaxis])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0978, 0.3031, 0.1394, 0.2099, 0.2063, 0.2098, 0.1076, 0.2316, 0.0298,\n",
       "        0.1968, 0.0261, 0.0561, 0.0848, 0.2727, 0.2320, 0.3355, 0.2739, 0.0056,\n",
       "        0.0301, 0.0953, 0.0889, 0.2483, 0.0063, 0.0231, 0.0009, 0.0924, 0.4782,\n",
       "        0.3251, 0.2092, 0.2881], device='cuda:0')"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.mean(dim = 0)[:D]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1024, 0.3083, 0.1548, 0.2167, 0.2263, 0.2134, 0.1191, 0.2376, 0.0462,\n",
       "        0.2211, 0.0391, 0.0645, 0.1074, 0.2926, 0.2355, 0.3374, 0.2798, 0.0250,\n",
       "        0.0395, 0.1016, 0.1004, 0.2553, 0.0321, 0.0384, 0.0269, 0.1083, 0.4753,\n",
       "        0.3296, 0.2227, 0.3098], device='cuda:0', grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vanilla_vae(test_data)[0].mean(dim = 0)[:D]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1913, 0.2338, 0.2076, 0.2199, 0.2306, 0.1890, 0.1805, 0.1945, 0.1051,\n",
       "        0.2321, 0.0976, 0.1389, 0.1652, 0.1922, 0.2341, 0.2330, 0.2048, 0.0390,\n",
       "        0.0929, 0.1692, 0.1755, 0.2236, 0.0499, 0.0923, 0.0152, 0.1863, 0.1593,\n",
       "        0.2244, 0.2096, 0.2350], device='cuda:0')"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.std(dim = 0)[:D]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0775, 0.0683, 0.1182, 0.1115, 0.0892, 0.0724, 0.1055, 0.1345, 0.0510,\n",
       "        0.1129, 0.0451, 0.0560, 0.0805, 0.1525, 0.1804, 0.1922, 0.0643, 0.0321,\n",
       "        0.0404, 0.0648, 0.0767, 0.1383, 0.0411, 0.0418, 0.0351, 0.1132, 0.0543,\n",
       "        0.1718, 0.0692, 0.1575], device='cuda:0', grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vanilla_vae(test_data)[0].std(dim = 0)[:D]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The gradients are a few epochs are good for selecting of features as the Gumbel trick. Maybe even better.\n",
    "In fact, a Vanilla VAE is just as good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nyu] *",
   "language": "python",
   "name": "conda-env-nyu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
