{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import functional as F\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "#from sklearn.manifold import TSNE\n",
    "\n",
    "#import math\n",
    "\n",
    "#import gc\n",
    "\n",
    "from utils import *\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "import seaborn as sns\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "cuda = True if torch.cuda.is_available() else False\n",
    "\n",
    "Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor\n",
    "\n",
    "device = torch.device(\"cuda:0\" if cuda else \"cpu\")\n",
    "#device = 'cpu'\n",
    "print(\"Device\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = 30\n",
    "N = 10000\n",
    "z_size = 8\n",
    "\n",
    "# really good results for vanilla VAE on synthetic data with EPOCHS set to 50, \n",
    "# but when running locally set to 10 for reasonable run times\n",
    "n_epochs = 600\n",
    "batch_size = 64\n",
    "lr = 0.0001\n",
    "b1 = 0.9\n",
    "b2 = 0.999\n",
    "\n",
    "global_t = 0.099\n",
    "k_lab = [D//10, D//6, D//3, D//2, D]\n",
    "trial_num = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = generate_synthetic_data_with_noise(N, z_size, D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = \"../data/models/final_run/\"\n",
    "# BASE_PATH = '/scratch/ns3429/sparse-subset/data/models/final_run/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_trial_model(trial_path, k):\n",
    "    if ('vanilla_vae_gumbel' in trial_path):\n",
    "        model = VAE_Gumbel(2*D, 100, 20, k = k, t = global_t) \n",
    "    if ('batching_gumbel_vae' in trial_path):\n",
    "        model = VAE_Gumbel_NInsta(2*D, 100, 20, k = k, t = global_t)\n",
    "    if ('globalgate_vae' in trial_path):\n",
    "        model = VAE_Gumbel_GlobalGate(2*D, 100, 20, k = k, t = global_t)\n",
    "    if ('runningstate_vae' in trial_path):\n",
    "        model = VAE_Gumbel_RunningState(2*D, 100, 20, k = k, t = global_t, alpha = 0.9)\n",
    "    if ('concrete_vae_nmsl' in trial_path):\n",
    "        model = ConcreteVAE_NMSL(2*D, 100, 20, k = k, t = global_t)\n",
    "    \n",
    "    model.load_state_dict(torch.load(trial_path))\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_model_metrics(model):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VAE_Gumbel(\n",
       "  (encoder): Sequential(\n",
       "    (0): Linear(in_features=60, out_features=100, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "  )\n",
       "  (enc_mean): Linear(in_features=100, out_features=20, bias=True)\n",
       "  (enc_logvar): Linear(in_features=100, out_features=20, bias=True)\n",
       "  (decoder): Sequential(\n",
       "    (0): Linear(in_features=20, out_features=100, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): Linear(in_features=100, out_features=60, bias=True)\n",
       "    (3): Sigmoid()\n",
       "  )\n",
       "  (weight_creator): Sequential(\n",
       "    (0): Linear(in_features=60, out_features=100, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=100, out_features=60, bias=True)\n",
       "    (3): LeakyReLU(negative_slope=0.01)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test model\n",
    "path = '../data/models/final_run/vanilla_vae_gumbel/k_15/model_trial_3.pt'\n",
    "model = VAE_Gumbel(2*D, 100, 20, k = 15, t = global_t) \n",
    "model.load_state_dict(torch.load(path))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = test_data[0:64, :]\n",
    "with torch.no_grad():\n",
    "    pred_df = model(test_df)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0464, 0.1195, 0.0845, 0.0104, 0.2252, 0.1259, 0.1879, 0.2976, 0.1553,\n",
       "        0.1303, 0.3214, 0.1200, 0.0780, 0.2892, 0.1563, 0.0764, 0.1087, 0.0170,\n",
       "        0.3132, 0.1194, 0.0414, 0.1190, 0.1890, 0.1809, 0.1659, 0.1510, 0.1903,\n",
       "        0.1344, 0.0871, 0.0294, 0.4809, 0.4847, 0.4540, 0.4661, 0.4507, 0.5386,\n",
       "        0.5251, 0.4553, 0.4645, 0.5043, 0.5350, 0.4467, 0.4940, 0.4733, 0.5062,\n",
       "        0.4916, 0.4410, 0.4825, 0.4733, 0.4785, 0.5255, 0.4801, 0.5315, 0.5335,\n",
       "        0.5443, 0.4986, 0.5396, 0.4663, 0.4663, 0.4903], device='cuda:0')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.mean(dim = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0605, 0.1226, 0.1053, 0.0253, 0.2312, 0.1258, 0.2084, 0.3063, 0.1771,\n",
       "        0.1592, 0.3263, 0.1122, 0.0983, 0.2907, 0.1670, 0.0844, 0.1208, 0.0189,\n",
       "        0.3198, 0.1345, 0.0441, 0.1405, 0.2189, 0.1823, 0.1709, 0.1352, 0.1966,\n",
       "        0.1574, 0.0859, 0.0503, 0.4701, 0.5047, 0.4484, 0.4648, 0.4346, 0.5511,\n",
       "        0.5150, 0.4591, 0.4863, 0.5043, 0.5335, 0.4692, 0.5127, 0.4659, 0.5057,\n",
       "        0.5039, 0.4515, 0.5015, 0.4748, 0.4784, 0.5431, 0.4873, 0.5155, 0.5153,\n",
       "        0.5320, 0.5046, 0.5208, 0.4845, 0.4921, 0.5073], device='cuda:0')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df.mean(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1876.1711, device='cuda:0')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.binary_cross_entropy(pred_df, test_df, reduction = 'sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bce_model(data, model):\n",
    "    test_loss = 0\n",
    "    inds = np.arange(test_data.shape[0])\n",
    "    with torch.no_grad():\n",
    "        for i in range(math.ceil(len(data)/batch_size)):\n",
    "            batch_ind = inds[i * batch_size : (i+1) * batch_size]\n",
    "            batch_data = data[batch_ind, :]\n",
    "\n",
    "            test_pred = model(batch_data)[0]\n",
    "\n",
    "\n",
    "            test_loss += F.binary_cross_entropy(test_pred, batch_data, reduction='sum')\n",
    "\n",
    "            del batch_data\n",
    "    return test_loss / data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(29.3722, device='cuda:0')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bce_model(test_data, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_logits_gumbel_vanilla_vae_gumbel(data, model):\n",
    "    all_logits = torch.zeros(data.shape[1], dtype = torch.float32)\n",
    "    all_subsets = torch.zeros(data.shape[1], dtype = torch.float32)\n",
    "    torch.tensor\n",
    "    with torch.no_grad():\n",
    "        for i in range(math.ceil(len(data)/batch_size)):\n",
    "            batch_ind = inds[i * batch_size : (i+1) * batch_size]\n",
    "            batch_data = data[batch_ind, :]\n",
    "\n",
    "            test_pred = model(batch_data)[0]\n",
    "            \n",
    "            logits = model.weight_creator(batch_data)\n",
    "            subsets = sample_subset(logits, model.k, model.t, separate = True)\n",
    "            \n",
    "            topk_logits = torch.topk(logits, k = model.k, dim = 1, sorted = True)[1]\n",
    "            one_hotted_top_k = torch.nn.functional.one_hot(top_k, num_classes = data.shape[1]).sum(dim = 1)\n",
    "            \n",
    "            max_idx = torch.argmax(subsets, 2, keepdim=True)\n",
    "            one_hot = Tensor(subsets.shape)\n",
    "            one_hot.zero_()\n",
    "            one_hot.scatter_(2, max_idx, 1)\n",
    "    \n",
    "    \n",
    "            all_logits += one_hotted_top_k.sum(dim = 0)\n",
    "            all_subsets += one_hot.sum(dim = (0, 1))\n",
    "            \n",
    "            \n",
    "    \n",
    "        all_logits /= train_data.shape[0]\n",
    "        all_subsets /= train_data.shape[0]\n",
    "    \n",
    "    return all_logits, all_subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_logits_gumbel_batching_vae_gumbel(data, model):\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nyu] *",
   "language": "python",
   "name": "conda-env-nyu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
